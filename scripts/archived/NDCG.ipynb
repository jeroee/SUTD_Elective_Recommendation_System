{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "## from week 6 lab\r\n",
    "def dcg_at_k(r, k, method=0):\r\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\r\n",
    "\r\n",
    "    Relevance is positive real values.  Can use binary\r\n",
    "    as the previous methods.\r\n",
    "\r\n",
    "    Example from\r\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\r\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\r\n",
    "    >>> dcg_at_k(r, 1)\r\n",
    "    3.0\r\n",
    "    >>> dcg_at_k(r, 1, method=1)\r\n",
    "    3.0\r\n",
    "    >>> dcg_at_k(r, 2)\r\n",
    "    5.0\r\n",
    "    >>> dcg_at_k(r, 2, method=1)\r\n",
    "    4.2618595071429155\r\n",
    "    >>> dcg_at_k(r, 10)\r\n",
    "    9.6051177391888114\r\n",
    "    >>> dcg_at_k(r, 11)\r\n",
    "    9.6051177391888114\r\n",
    "\r\n",
    "    Args:\r\n",
    "        r: Relevance scores (list or numpy) in rank order\r\n",
    "            (first element is the first item)\r\n",
    "        k: Number of results to consider\r\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        Discounted cumulative gain\r\n",
    "    \"\"\"\r\n",
    "    import numpy as np\r\n",
    "    r = np.asfarray(r)[:k]\r\n",
    "    if r.size: ## why is this r.size? when will this be false?\r\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\r\n",
    "    return 0."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## from week 6 lab\r\n",
    "def ndcg_at_k(r, k, method=0):\r\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\r\n",
    "\r\n",
    "    Relevance is positive real values.  Can use binary\r\n",
    "    as the previous methods.\r\n",
    "\r\n",
    "    Example from\r\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\r\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\r\n",
    "    >>> ndcg_at_k(r, 1)\r\n",
    "    1.0\r\n",
    "    >>> r = [2, 1, 2, 0]\r\n",
    "    >>> ndcg_at_k(r, 4)\r\n",
    "    0.9203032077642922\r\n",
    "    >>> ndcg_at_k(r, 4, method=1)\r\n",
    "    0.96519546960144276\r\n",
    "    >>> ndcg_at_k([0], 1)\r\n",
    "    0.0\r\n",
    "    >>> ndcg_at_k([1], 2)\r\n",
    "    1.0\r\n",
    "\r\n",
    "    Args:\r\n",
    "        r: Relevance scores (list or numpy) in rank order\r\n",
    "            (first element is the first item)\r\n",
    "        k: Number of results to consider\r\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\r\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        Normalized discounted cumulative gain\r\n",
    "    \"\"\"\r\n",
    "    import numpy as np\r\n",
    "\r\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\r\n",
    "    if not dcg_max:\r\n",
    "        return 0.\r\n",
    "    # print('For k is {}, DCG scorce is {}'.format(k,dcg_at_k(r, k, method)))\r\n",
    "    # print('For k is {}, IDCG scorce is {}'.format(k,dcg_max))\r\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def assigningBM25ScoreToRelevantAndRetrieved(_bm25ScoreDf, relevantDocsList):\r\n",
    "    \"\"\"[summary]\r\n",
    "    This function helps to assign zero values to those non-relevant and retrieved documents\r\n",
    "    It retents the score of those relevant and retrieved\r\n",
    "\r\n",
    "    Args:\r\n",
    "        _bm25ScoreDf ([dataframe]): [a dataframe where rows are modules and columns is the bm25 scores]\r\n",
    "        relevantAndRetrievedDocs ([list]): [list of modules based on the golden standard(idea outcome based on survey)]\r\n",
    "    \"\"\"\r\n",
    "    df = _bm25ScoreDf.copy(deep = False)\r\n",
    "    irrelevantAndRetrievedDocsList = list(set(df.index) - set(relevantDocsList))\r\n",
    "    \r\n",
    "    for relevantAndRetrievedDoc in irrelevantAndRetrievedDocsList:\r\n",
    "        df.loc[relevantAndRetrievedDoc]['bm25Score'] = 0\r\n",
    "    \"\"\"[summary]\r\n",
    "    output is a df with score that are retrieved and relevant(relevant depends on the gold standard)\r\n",
    "    \"\"\"\r\n",
    "    return(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def NDCGWithVariousK(retrievedDocsDf,listOfRelevantDocs, exportResults = 0, queryNum = '', fileName = 'test'):\r\n",
    "    \"\"\"[summary]\r\n",
    "    This function compute the NDGC at vaious K\r\n",
    "\r\n",
    "    Args:\r\n",
    "        retrievedDocsDf ([dataframe]): [dataframe of retrieved documents and it's bm25 score]\r\n",
    "        listOfRelevantDocs ([list]): [list of relevant Documents based on gold standard]\r\n",
    "        exportResults (int, optional): [to determine to export ndcg results]. Defaults to 0 and 1 to export ndgc score\r\n",
    "        fileName (str, optional): [fileName to be exported ideally it should be the \"ndcg_score_'model name']. Defaults to 'test'.\r\n",
    "    \"\"\"\r\n",
    "    ## assign zero values to those non-relevant and retrieved documents, It retain the score of those relevant and retrieved\r\n",
    "    BM25ScoreToRelevantAndRetrieved = assigningBM25ScoreToRelevantAndRetrieved(retrievedDocsDf,listOfRelevantDocs)\r\n",
    "    ## obtain the score of the BM25 of the relevant and retrieved modules\r\n",
    "    BM25ScoreToRelevantAndRetrievedScoreList = list(BM25ScoreToRelevantAndRetrieved.bm25Score)\r\n",
    "    \r\n",
    "    ## dict to save NDCGScore ie {k(ranking):NDCG Score}\r\n",
    "    NDCGScoreDict = {}\r\n",
    "    for i in range(1,len(BM25ScoreToRelevantAndRetrievedScoreList)+1):\r\n",
    "        ndcg_at_kScore = ndcg_at_k(BM25ScoreToRelevantAndRetrievedScoreList,i)\r\n",
    "        # print('For k is {}, NDCG scorce is {}\\n'.format(i,ndcg_at_kScore))\r\n",
    "        NDCGScoreDict[i] = ndcg_at_kScore\r\n",
    "    \r\n",
    "    ## convert dict to df for easier sorting analysis of the scores and exporting it to csv\r\n",
    "    import pandas as pd\r\n",
    "    NDCGDf = pd.DataFrame.from_dict(NDCGScoreDict,orient='index',columns=['NDCGScore{}'.format(queryNum)])\r\n",
    "    NDCGDf.reset_index(inplace = True)\r\n",
    "    ## rename the column to k columns \r\n",
    "    NDCGDf.rename(columns={\"index\": \"k\"}, inplace = True)\r\n",
    "    \r\n",
    "    ## to export the ndcg scores to csv if exportResults == 1\r\n",
    "    if exportResults == 1:\r\n",
    "        fileName = 'ndcg_score_{}.csv'.format(fileName)\r\n",
    "        NDCGDf.to_csv('../results/ndcg_score/{}'.format(fileName))\r\n",
    "    return(NDCGDf)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Toy Problem formulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    \"Test Case : the retrievedDocScore\"\r\n",
    "    ## assume docs are not in bm25 scorce order\r\n",
    "    retrievedDocs = ['D','C', 'B','A'] \r\n",
    "    retrievedDocsScore = [0.43, 0.26, 0.03, 0.37]\r\n",
    "    ## I realised that the score should be in ascending order of bm25 score hence I made some changes to fit our use case\r\n",
    "    # retrievedDocsScore = [0.43,  0.37, 0.26, 0.03]\r\n",
    "\r\n",
    "    ## creating a retrievedDocsDf for test cases\r\n",
    "    ## this should be the same format of the bm25 output\r\n",
    "    retrievedDocsDict = {}\r\n",
    "    for index in range(len(retrievedDocs)):\r\n",
    "        retrievedDocsDict[retrievedDocs[index]] = retrievedDocsScore[index]\r\n",
    "    import pandas as pd\r\n",
    "    retrievedDocsDf1 = pd.DataFrame.from_dict(retrievedDocsDict,orient='index',columns = ['bm25Score'])\r\n",
    "\r\n",
    "    print('BM25 output:')\r\n",
    "    retrievedDocsDf1\r\n",
    "\r\n",
    "    \"Test Case : the retrievedDocScore\"\r\n",
    "    ## assume docs are not in bm25 scorce order\r\n",
    "    retrievedDocs = ['C','D', 'B','A'] \r\n",
    "    retrievedDocsScore = [0.5, 0.3, 0.2, 0.1]\r\n",
    "    ## I realised that the score should be in ascending order of bm25 score hence I made some changes to fit our use case\r\n",
    "    # retrievedDocsScore = [0.43,  0.37, 0.26, 0.03]\r\n",
    "\r\n",
    "    ## creating a retrievedDocsDf for test cases\r\n",
    "    ## this should be the same format of the bm25 output\r\n",
    "    retrievedDocsDict = {}\r\n",
    "    for index in range(len(retrievedDocs)):\r\n",
    "        retrievedDocsDict[retrievedDocs[index]] = retrievedDocsScore[index]\r\n",
    "    import pandas as pd\r\n",
    "    retrievedDocsDf2 = pd.DataFrame.from_dict(retrievedDocsDict,orient='index',columns = ['bm25Score'])\r\n",
    "\r\n",
    "    print('BM25 output:')\r\n",
    "    retrievedDocsDf2\r\n",
    "    \"Test Case : The Relevant Docs\"\r\n",
    "    relevantDocs1 = ['B','D','E']\r\n",
    "    print('List of relevant Docs: {}'.format(relevantDocs1))\r\n",
    "    relevantDocs2 = ['A','C']\r\n",
    "    print('List of relevant Docs: {}'.format(relevantDocs2))\r\n",
    "\r\n",
    "    retrievedlist = [retrievedDocsDf1,retrievedDocsDf2]\r\n",
    "    relevantlist =[relevantDocs1,relevantDocs2]\r\n",
    "    \r\n",
    "    ## test case\r\n",
    "    import pandas as pd\r\n",
    "    ## this index is meant to keep track of the NDCG score of each query\r\n",
    "    queryIndex = 0\r\n",
    "    for retrieved in retrievedlist:\r\n",
    "    ## to compute the NDCG of a single query\r\n",
    "        NDCGWithVariousKdf = NDCGWithVariousK(retrieved,relevantlist[queryIndex],0,queryIndex)\r\n",
    "    ## if this is 1st NDCG score been compute, make it's df to NDCG df else merge with the current overall NDGC df\r\n",
    "        if queryIndex == 0:\r\n",
    "            NDCGDf = NDCGWithVariousKdf\r\n",
    "        else:\r\n",
    "            NDCGDf = pd.merge(NDCGDf, NDCGWithVariousKdf, on=[\"k\"])\r\n",
    "        queryIndex += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BM25 output:\n",
      "BM25 output:\n",
      "List of relevant Docs: ['B', 'D', 'E']\n",
      "List of relevant Docs: ['A', 'C']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def clean_elective_names(relevant_results):\r\n",
    "    # clean up the relevant course names \r\n",
    "\r\n",
    "    #https://stackoverflow.com/questions/2582138/finding-and-replacing-elements-in-a-list\r\n",
    "    try:\r\n",
    "        relevant_results = relevant_results.split(',')\r\n",
    "        relevant_results = [x.replace(\"'\",'') for x in relevant_results]\r\n",
    "        relevant_results = [x.replace(\"[\",'') for x in relevant_results]\r\n",
    "        relevant_results = [x.replace(\"]\",'') for x in relevant_results]\r\n",
    "    ## this is required as apart from the index 0 module the other modules still retain a space inform of them\r\n",
    "        relevant_results2 = [x.replace(\" \",'',1) for x in relevant_results if x != relevant_results[0]]\r\n",
    "    ## thus the next 2 lines of code help to reinsert the 0th index modules and reassign relevant_results2 to relevant_results\r\n",
    "        relevant_results2.insert(0,relevant_results[0])\r\n",
    "        relevant_results = relevant_results2\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    replacements = {\r\n",
    "        ' 50.035 Computer Vision': '50.035 Computer Vision'\r\n",
    "        ,'50.043 Database Systems / Database and Big Data Systems (for class 2021)': '50.043 Database Systems'\r\n",
    "        }\r\n",
    "\r\n",
    "    relevant_results = [replacements.get(x, x) for x in relevant_results]\r\n",
    "    \r\n",
    "    if '40.302 Advanced Optim/ 40.305 Advanced Stochastic' in relevant_results:\r\n",
    "        relevant_results.remove('40.302 Advanced Optim/ 40.305 Advanced Stochastic')\r\n",
    "        relevant_results.append('40.302 Advanced Topics in Optimisation#')\r\n",
    "        relevant_results.append('40.305 Advanced Topics in Stochastic Modelling#')\r\n",
    "    return relevant_results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def displayNdcgAt10(queryCount,query_val,NDCGWithVariousKdf):\r\n",
    "    \"\"\"[summary]\r\n",
    "    to print the result of ndcg at 10 for every query\r\n",
    "\r\n",
    "    Args:\r\n",
    "        queryCount ([int]): [description] counter to indicate wht query it is at wihin query_val's querySample columns\r\n",
    "        NDCGWithVariousKdf ([dataframe]): [description] df with a single query's ndcg score at various k\r\n",
    "    \"\"\"\r\n",
    "    queryColumn = 'NDCGScore{}'.format(queryCount)\r\n",
    "    ndcgAt10 = NDCGWithVariousKdf[queryColumn][9]\r\n",
    "    ndcgAt10 = round(ndcgAt10, 5)\r\n",
    "    print(f\"query: {query_val['querySample'][queryCount]}\".ljust(100, \" \"), f\"NDCG@10 {ndcgAt10}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## function to compute the NDCG for cosine simliarities for model 1\r\n",
    "def get_NDCG_cosine_no_expan(query_val,tf):\r\n",
    "    import CosineSimilarity_no_query_expan\r\n",
    "    ## compute Cosine simliarities score\r\n",
    "    cosineSimDf = CosineSimilarity_no_query_expan.rankedModuleOfCosineSim(query_val,tf)\r\n",
    "    cosineSimDf = cosineSimDf.T\r\n",
    "\r\n",
    "    ## this section help to compute and obtain the NDCG for each query and store in df\r\n",
    "    import pandas as pd\r\n",
    "    queryCount = 0\r\n",
    "    NDCGDf = 0\r\n",
    "    for query,row in cosineSimDf.iterrows():\r\n",
    "        ## create the df for retrieved docs and it's score\r\n",
    "            retrievedDocsDict = {}\r\n",
    "            cleanedElectives = clean_elective_names(row['topModules'])\r\n",
    "            for index in range(len(row['topModules'])):\r\n",
    "                retrievedDocsDict[cleanedElectives[index]] = row['topModulesScore'][index]\r\n",
    "            import pandas as pd\r\n",
    "            retrievedDocsDf = pd.DataFrame.from_dict(retrievedDocsDict,orient='index',columns = ['bm25Score'])\r\n",
    "        \r\n",
    "        ## cleaned golden/vaildation set modules\r\n",
    "            validModules = clean_elective_names(query_val['expectedElectivesInOrder'][queryCount])\r\n",
    "        ## to compute the NDCG of a single query\r\n",
    "            NDCGWithVariousKdf = NDCGWithVariousK(retrievedDocsDf,validModules,0,queryCount)\r\n",
    "        ## if this is 1st NDCG score been compute, make it's df to NDCG df else merge with the current overall NDGC df\r\n",
    "            if queryCount == 0:\r\n",
    "                NDCGDf = NDCGWithVariousKdf\r\n",
    "            else:\r\n",
    "                NDCGDf = pd.merge(NDCGDf, NDCGWithVariousKdf, on=[\"k\"])\r\n",
    "                \r\n",
    "        ## print query and NDCG score at k =10\r\n",
    "            displayNdcgAt10(queryCount,query_val,NDCGWithVariousKdf)\r\n",
    "        ## update the query index by 1\r\n",
    "            queryCount += 1\r\n",
    "            \r\n",
    "    ## return a df with all the ndcg results\r\n",
    "    \r\n",
    "    return(NDCGDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## function to compute the NDCG for cosine simliarities for model 2 and 3\r\n",
    "def get_NDCG_cosine(query_val,tf):\r\n",
    "    import CosineSimilarity\r\n",
    "    ## compute Cosine simliarities score\r\n",
    "    cosineSimDf = CosineSimilarity.rankedModuleOfCosineSim(query_val,tf)\r\n",
    "    cosineSimDf = cosineSimDf.T\r\n",
    "\r\n",
    "    ## this section help to compute and obtain the NDCG for each query and store in df\r\n",
    "    import pandas as pd\r\n",
    "    queryCount = 0\r\n",
    "    NDCGDf = 0\r\n",
    "    for query,row in cosineSimDf.iterrows():\r\n",
    "        ## create the df for retrieved docs and it's score\r\n",
    "            retrievedDocsDict = {}\r\n",
    "            cleanedElectives = clean_elective_names(row['topModules'])\r\n",
    "            for index in range(len(row['topModules'])):\r\n",
    "                retrievedDocsDict[cleanedElectives[index]] = row['topModulesScore'][index]\r\n",
    "            import pandas as pd\r\n",
    "            retrievedDocsDf = pd.DataFrame.from_dict(retrievedDocsDict,orient='index',columns = ['bm25Score'])\r\n",
    "        \r\n",
    "        ## cleaned golden/vaildation set modules\r\n",
    "            validModules = clean_elective_names(query_val['expectedElectivesInOrder'][queryCount])\r\n",
    "        ## to compute the NDCG of a single query\r\n",
    "            NDCGWithVariousKdf = NDCGWithVariousK(retrievedDocsDf,validModules,0,queryCount)\r\n",
    "        ## if this is 1st NDCG score been compute, make it's df to NDCG df else merge with the current overall NDGC df\r\n",
    "            if queryCount == 0:\r\n",
    "                NDCGDf = NDCGWithVariousKdf\r\n",
    "            else:\r\n",
    "                NDCGDf = pd.merge(NDCGDf, NDCGWithVariousKdf, on=[\"k\"])\r\n",
    "                \r\n",
    "        ## print query and NDCG score at k =10\r\n",
    "            displayNdcgAt10(queryCount,query_val,NDCGWithVariousKdf)\r\n",
    "        ## update the query index by 1\r\n",
    "            queryCount += 1\r\n",
    "            \r\n",
    "    ## return a df with all the ndcg results\r\n",
    "    \r\n",
    "    return(NDCGDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## function to compute the NDCG for bm25basic for model 4\r\n",
    "## model 4 BM25 Basic (without query expansion, course information)\r\n",
    "def get_NDCG_BM25BasicNoExpan(query_val,tf,tf_norm,idf):\r\n",
    "    import time\r\n",
    "    import basic_bm25\r\n",
    "    import utils.query_processing\r\n",
    "    \r\n",
    "    ## vairables required for basic_bm25 function\r\n",
    "    vocab = tf.index.tolist()\r\n",
    "    total_length = tf.to_numpy().sum()\r\n",
    "    avg_doc_len = total_length / len(tf.columns) # average document length across all courses\r\n",
    "    \r\n",
    "    ## this section help to compute and obtain the NDCG for each query and store in df\r\n",
    "    import pandas as pd\r\n",
    "    queryCount = 0\r\n",
    "    NDCGDf = 0\r\n",
    "    totalTime = 0\r\n",
    "    for index,row in query_val.iterrows():\r\n",
    "        query = row['querySample']\r\n",
    "        query = utils.query_processing.process_query(query)\r\n",
    "    ## compute basic_bm25 score\r\n",
    "        start = time.time()\r\n",
    "        retrievedDocs, rankedLs = basic_bm25.get_result(query,tf,tf_norm,idf,vocab,avg_doc_len)\r\n",
    "        end =  time.time()- start\r\n",
    "        totalTime += end\r\n",
    "    ## converting moduleNScore to dataframe    \r\n",
    "        retrievedDf = pd.DataFrame.from_dict(retrievedDocs,orient='index',columns = ['bm25Score'])        \r\n",
    "    ## cleaned golden/vaildation set modules\r\n",
    "        validModules = clean_elective_names(query_val['expectedElectivesInOrder'][queryCount])\r\n",
    "    ## to compute the NDCG of a single query\r\n",
    "        NDCGWithVariousKdf = NDCGWithVariousK(retrievedDf,validModules,0,queryCount)\r\n",
    "        \r\n",
    "    ## if this is 1st NDCG score been compute, make it's df to NDCG df else merge with the current overall NDGC df\r\n",
    "        if queryCount == 0:\r\n",
    "            NDCGDf = NDCGWithVariousKdf\r\n",
    "        else:\r\n",
    "            NDCGDf = pd.merge(NDCGDf, NDCGWithVariousKdf, on=[\"k\"])\r\n",
    "        \r\n",
    "    ## print query and NDCG score at k =10\r\n",
    "        displayNdcgAt10(queryCount,query_val,NDCGWithVariousKdf)\r\n",
    "    ## update the query index by 1\r\n",
    "        queryCount += 1\r\n",
    "        \r\n",
    "        ## print only when the last query is computed\r\n",
    "        if queryCount == (len(query_val)):\r\n",
    "            averageQueryTime = totalTime/queryCount\r\n",
    "            print('Average Time for {} number of queries : {}'.format(queryCount,averageQueryTime))\r\n",
    "    ## return a df with all the ndcg results\r\n",
    "    \r\n",
    "    return(NDCGDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## function to compute the NDCG for bm25basic for model 5 and 6\r\n",
    "## model 5 BM25 Basic (query expansion, course information)\r\n",
    "## model 6 BM25 Basic (query expansion, course information + survey (50%))\r\n",
    "## model 7 Bm25 with Reformulation (query expansion, course information + survey (50%))\r\n",
    "\r\n",
    "def get_NDCG_BM25Basic(query_val,tf,tf_norm,idf):\r\n",
    "    import basic_bm25\r\n",
    "    import utils.query_processing\r\n",
    "    import time\r\n",
    "    \r\n",
    "    ## vairables required for basic_bm25 function\r\n",
    "    vocab = tf.index.tolist()\r\n",
    "    total_length = tf.to_numpy().sum()\r\n",
    "    avg_doc_len = total_length / len(tf.columns) # average document length across all courses\r\n",
    "    \r\n",
    "    ## this section help to compute and obtain the NDCG for each query and store in df\r\n",
    "    import pandas as pd\r\n",
    "    queryCount = 0\r\n",
    "    NDCGDf = 0\r\n",
    "    totalTime = 0\r\n",
    "    for index,row in query_val.iterrows():\r\n",
    "        query = row['querySample']\r\n",
    "        query = utils.query_processing.process_query(query)\r\n",
    "        \r\n",
    "    ## for query expansion\r\n",
    "        glove_kv = '../pretrained_corpus/glove_6B_300d.kv'   # pretrained vectors for query expansion\r\n",
    "        topn = 3\r\n",
    "        query = utils.query_processing.expand_query(query,glove_kv,topn)\r\n",
    "        \r\n",
    "    ## compute basic_bm25 score and start the timer for querying\r\n",
    "        start = time.time()\r\n",
    "        retrievedDocs, rankedLs = basic_bm25.get_result(query,tf,tf_norm,idf,vocab,avg_doc_len)\r\n",
    "        end =  time.time()- start\r\n",
    "        totalTime += end\r\n",
    "    ## converting moduleNScore to dataframe    \r\n",
    "        retrievedDf = pd.DataFrame.from_dict(retrievedDocs,orient='index',columns = ['bm25Score'])        \r\n",
    "    ## cleaned golden/vaildation set modules\r\n",
    "        validModules = clean_elective_names(query_val['expectedElectivesInOrder'][queryCount])\r\n",
    "    ## to compute the NDCG of a single query\r\n",
    "        NDCGWithVariousKdf = NDCGWithVariousK(retrievedDf,validModules,0,queryCount)\r\n",
    "        \r\n",
    "    ## if this is 1st NDCG score been compute, make it's df to NDCG df else merge with the current overall NDGC df\r\n",
    "        if queryCount == 0:\r\n",
    "            NDCGDf = NDCGWithVariousKdf\r\n",
    "        else:\r\n",
    "            NDCGDf = pd.merge(NDCGDf, NDCGWithVariousKdf, on=[\"k\"])\r\n",
    "    ## print query and NDCG score at k =10\r\n",
    "        displayNdcgAt10(queryCount,query_val,NDCGWithVariousKdf)\r\n",
    "    ## update the query index by 1\r\n",
    "        queryCount += 1\r\n",
    "    \r\n",
    "    ## print only when the last query is computed\r\n",
    "        if queryCount == (len(query_val)):\r\n",
    "            averageQueryTime = totalTime/queryCount\r\n",
    "            print('Average Time for {} number of queries : {}'.format(queryCount,averageQueryTime))\r\n",
    "    ## return a df with all the ndcg results\r\n",
    "    \r\n",
    "    return(NDCGDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "## function to compute the NDCG for bm25basic for model 8\r\n",
    "## model 8 Bm25 with Reformulation and Pseudo Relevance Feedback (query expansion, course information + survey (50%))\r\n",
    "def get_NDCG_BM25WPseudo(query_val,tf,tf_norm,idf):\r\n",
    "    import bm25_with_pseudo_relevance\r\n",
    "    import utils.query_processing\r\n",
    "    import time\r\n",
    "    import pandas as pd\r\n",
    "    ## vairables required for basic_bm25 function\r\n",
    "    vocab = tf.index.tolist()\r\n",
    "    total_length = tf.to_numpy().sum()\r\n",
    "    avg_doc_len = total_length / len(tf.columns) # average document length across all courses\r\n",
    "    norm_association_matrix = pd.read_csv('../data/trained_scores/norm_association_matrix_trained.csv', header = 0, index_col = 0)\r\n",
    "    df = pd.read_csv('../data/trained_scores/course_info_with_survey_df_trained.csv', header=0, index_col=0)\r\n",
    "    \r\n",
    "    ## this section help to compute and obtain the NDCG for each query and store in df\r\n",
    "    queryCount = 0\r\n",
    "    NDCGDf = 0\r\n",
    "    totalTime = 0\r\n",
    "    for index,row in query_val.iterrows():\r\n",
    "        query = row['querySample']\r\n",
    "    ## do not run glove_kv, topn, expand_query for  get_NDCG_BM25WPseudo\r\n",
    "        \r\n",
    "    ## compute basic_bm25 score and start the timer for querying\r\n",
    "        start = time.time()\r\n",
    "        retrievedDocs, rankedLs = bm25_with_pseudo_relevance.bm25_pseudo_relevance_back(query, df, tf, tf_norm, idf, norm_association_matrix, vocab, avg_doc_len, k=10)\r\n",
    "        end =  time.time()- start\r\n",
    "        totalTime += end\r\n",
    "    ## converting moduleNScore to dataframe    \r\n",
    "        retrievedDf = pd.DataFrame.from_dict(retrievedDocs,orient='index',columns = ['bm25Score'])        \r\n",
    "    ## cleaned golden/vaildation set modules\r\n",
    "        validModules = clean_elective_names(query_val['expectedElectivesInOrder'][queryCount])\r\n",
    "    ## to compute the NDCG of a single query\r\n",
    "        NDCGWithVariousKdf = NDCGWithVariousK(retrievedDf,validModules,0,queryCount)\r\n",
    "        \r\n",
    "    ## if this is 1st NDCG score been compute, make it's df to NDCG df else merge with the current overall NDGC df\r\n",
    "        if queryCount == 0:\r\n",
    "            NDCGDf = NDCGWithVariousKdf\r\n",
    "        else:\r\n",
    "            NDCGDf = pd.merge(NDCGDf, NDCGWithVariousKdf, on=[\"k\"])\r\n",
    "    ## print query and NDCG score at k =10\r\n",
    "        displayNdcgAt10(queryCount,query_val,NDCGWithVariousKdf)\r\n",
    "    ## update the query index by 1\r\n",
    "        queryCount += 1\r\n",
    "        \r\n",
    "    ## print only when the last query is computed\r\n",
    "        if queryCount == (len(query_val)):\r\n",
    "            averageQueryTime = totalTime/queryCount\r\n",
    "            print('Average Time for {} number of queries : {}'.format(queryCount,averageQueryTime))\r\n",
    "    ## return a df with all the ndcg results\r\n",
    "    \r\n",
    "    return(NDCGDf)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    # model 1 2 and 3\r\n",
    "    import pandas as pd\r\n",
    "    if True:\r\n",
    "        ## model 1 Cosine Similarity (without and with query expansion, course information + (50% survey))\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 1 Cosine Similarity (without query expansion, only with course information data)')\r\n",
    "        tf = pd.read_csv('../data/course_info_scores/course_info_tf.csv', index_col = 0)\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        model1NDCG = get_NDCG_cosine_no_expan(query_val,tf)\r\n",
    "        model1NDCGAverage = model1NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model1NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel1.csv')\r\n",
    "        print(\"Average NDCG@10 for model 1: {}\".format(round(model1NDCGAverage.iloc[9],5)))\r\n",
    "    if True:\r\n",
    "        ## model 2 Cosine Similarity (with query expansion, only with course information data)\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 2 Cosine Similarity (with query expansion, only with course information data)')\r\n",
    "        tf = pd.read_csv('../data/course_info_scores/course_info_tf.csv', index_col = 0)\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        model2NDCG = get_NDCG_cosine(query_val,tf)\r\n",
    "        model2NDCGAverage = model2NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model2NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel2.csv')\r\n",
    "        print(\"Average NDCG@10 for model 2: {}\".format(round(model2NDCGAverage.iloc[9],5)))\r\n",
    "        \r\n",
    "        ## model 3 Cosine Similarity (with query expansion, with course information data and 50% of survey data)\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 3 Cosine Similarity (with query expansion, with course information data and 50% of survey data)')\r\n",
    "        tf = pd.read_csv('../data/course_info_with_survey_scores/course_info_with_survey_tf.csv', index_col = 0)\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        model3NDCG = get_NDCG_cosine(query_val,tf)\r\n",
    "        model3NDCGAverage = model3NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model3NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel3.csv')\r\n",
    "        print(\"Average NDCG@10 for model 3: {}\".format(round(model3NDCGAverage.iloc[9],5)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "########################################################################################################################################################################################################\n",
      "Calculating NDCCG for Model 1 Cosine Similarity (without query expansion, only with course information data)\n",
      "\n",
      "Current computing Query: network, term, model, technology, probability\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: term, different, skill, mongodb, long\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: logistics, analysis, operation, basic, r\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: esd, network, evaluate, program, r\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: operation, basic, evaluation, price, evaluate\n",
      "Number of terms in corpus: 13\n",
      "\n",
      "Current computing Query: infrastructure, metric, pytorch, model, client\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: approach, logistics, shag, infrastructure, equity\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: data, sql, different, analytics, model\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: computational, best, server, certain, ec\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: sklearn, metric, demand, schedule, fundamental\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: digitalisation, skill, long, technology, aviation\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: r, hidden, artificial, schedule, simulate\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: optimisation, decision, risk, aws, jupyter\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: decentralizedapp, equity, math, ethereum, technology\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: financial, value, metric, optimize, analysis\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: risk, certain, computational, approach, c\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: markov, supply, hidden, computational, payoff\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: finance, value, long, average, business\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: financial, spark, science, focus, search\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: supply, notebook, fundamental, know, basic\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: r, linear, ethereum, c, machine\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: science, future, problem, demand, pytorch\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: r, ec, kera, opponent, model\n",
      "Number of terms in corpus: 3\n",
      "\n",
      "Current computing Query: markov, descent, algebra, math, research\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: clojurescript, ai, analysis, background, science\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: optimisation, opencv, risk, chain, urban\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: maing, descent, science, clojurescript, knowledge\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: schedule, gradient, airport, analysis, system\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: logistics, business, strategy, analytics, math\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: program, future, kera, ec, concept\n",
      "Number of terms in corpus: 6\n",
      "average Querying Time: 1.570597775777181\n",
      "query: network, term, model, technology, probability                                                 NDCG@10 0.40563\n",
      "query: term, different, skill, mongodb, long                                                         NDCG@10 0.31546\n",
      "query: logistics, analysis, operation, basic, r                                                      NDCG@10 0.83676\n",
      "query: esd, network, evaluate, program, r                                                            NDCG@10 0.39238\n",
      "query: operation, basic, evaluation, price, evaluate                                                 NDCG@10 0.36065\n",
      "query: infrastructure, metric, pytorch, model, client                                                NDCG@10 0.73776\n",
      "query: approach, logistics, shag, infrastructure, equity                                             NDCG@10 0.82853\n",
      "query: data, sql, different, analytics, model                                                        NDCG@10 0.94621\n",
      "query: computational, best, server, certain, ec                                                      NDCG@10 0.33744\n",
      "query: sklearn, metric, demand, schedule, fundamental                                                NDCG@10 0.78451\n",
      "query: digitalisation, skill, long, technology, aviation                                             NDCG@10 0.56595\n",
      "query: r, hidden, artificial, schedule, simulate                                                     NDCG@10 0.89274\n",
      "query: optimisation, decision, risk, aws, jupyter                                                    NDCG@10 0.89381\n",
      "query: decentralizedapp, equity, math, ethereum, technology                                          NDCG@10 0.82038\n",
      "query: financial, value, metric, optimize, analysis                                                  NDCG@10 0.72978\n",
      "query: risk, certain, computational, approach, c                                                     NDCG@10 0.8527\n",
      "query: markov, supply, hidden, computational, payoff                                                 NDCG@10 0.82593\n",
      "query: finance, value, long, average, business                                                       NDCG@10 0.57218\n",
      "query: financial, spark, science, focus, search                                                      NDCG@10 0.5556\n",
      "query: supply, notebook, fundamental, know, basic                                                    NDCG@10 0.81872\n",
      "query: r, linear, ethereum, c, machine                                                               NDCG@10 1.0\n",
      "query: science, future, problem, demand, pytorch                                                     NDCG@10 0.80527\n",
      "query: r, ec, kera, opponent, model                                                                  NDCG@10 0.87602\n",
      "query: markov, descent, algebra, math, research                                                      NDCG@10 0.97762\n",
      "query: clojurescript, ai, analysis, background, science                                              NDCG@10 0.84642\n",
      "query: optimisation, opencv, risk, chain, urban                                                      NDCG@10 0.95568\n",
      "query: maing, descent, science, clojurescript, knowledge                                             NDCG@10 0.8841\n",
      "query: schedule, gradient, airport, analysis, system                                                 NDCG@10 0.77461\n",
      "query: logistics, business, strategy, analytics, math                                                NDCG@10 0.88691\n",
      "query: program, future, kera, ec, concept                                                            NDCG@10 0.71152\n",
      "Average NDCG@10 for model 1: 0.73971\n",
      "########################################################################################################################################################################################################\n",
      "Calculating NDCCG for Model 2 Cosine Similarity (with query expansion, only with course information data)\n",
      "\n",
      "Current computing Query: network, term, model, technology, probability\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: term, different, skill, mongodb, long\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: logistics, analysis, operation, basic, r\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: esd, network, evaluate, program, r\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: operation, basic, evaluation, price, evaluate\n",
      "Number of terms in corpus: 13\n",
      "\n",
      "Current computing Query: infrastructure, metric, pytorch, model, client\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: approach, logistics, shag, infrastructure, equity\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: data, sql, different, analytics, model\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: computational, best, server, certain, ec\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: sklearn, metric, demand, schedule, fundamental\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: digitalisation, skill, long, technology, aviation\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: r, hidden, artificial, schedule, simulate\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: optimisation, decision, risk, aws, jupyter\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: decentralizedapp, equity, math, ethereum, technology\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: financial, value, metric, optimize, analysis\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: risk, certain, computational, approach, c\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: markov, supply, hidden, computational, payoff\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: finance, value, long, average, business\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: financial, spark, science, focus, search\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: supply, notebook, fundamental, know, basic\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: r, linear, ethereum, c, machine\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: science, future, problem, demand, pytorch\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: r, ec, kera, opponent, model\n",
      "Number of terms in corpus: 3\n",
      "\n",
      "Current computing Query: markov, descent, algebra, math, research\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: clojurescript, ai, analysis, background, science\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: optimisation, opencv, risk, chain, urban\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: maing, descent, science, clojurescript, knowledge\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: schedule, gradient, airport, analysis, system\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: logistics, business, strategy, analytics, math\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: program, future, kera, ec, concept\n",
      "Number of terms in corpus: 6\n",
      "################################\n",
      "average Querying Time: 1.210910709698995\n",
      "query: network, term, model, technology, probability                                                 NDCG@10 0.40563\n",
      "query: term, different, skill, mongodb, long                                                         NDCG@10 0.31546\n",
      "query: logistics, analysis, operation, basic, r                                                      NDCG@10 0.83676\n",
      "query: esd, network, evaluate, program, r                                                            NDCG@10 0.39238\n",
      "query: operation, basic, evaluation, price, evaluate                                                 NDCG@10 0.36065\n",
      "query: infrastructure, metric, pytorch, model, client                                                NDCG@10 0.73776\n",
      "query: approach, logistics, shag, infrastructure, equity                                             NDCG@10 0.82853\n",
      "query: data, sql, different, analytics, model                                                        NDCG@10 0.94621\n",
      "query: computational, best, server, certain, ec                                                      NDCG@10 0.33744\n",
      "query: sklearn, metric, demand, schedule, fundamental                                                NDCG@10 0.78451\n",
      "query: digitalisation, skill, long, technology, aviation                                             NDCG@10 0.56595\n",
      "query: r, hidden, artificial, schedule, simulate                                                     NDCG@10 0.89274\n",
      "query: optimisation, decision, risk, aws, jupyter                                                    NDCG@10 0.89381\n",
      "query: decentralizedapp, equity, math, ethereum, technology                                          NDCG@10 0.82038\n",
      "query: financial, value, metric, optimize, analysis                                                  NDCG@10 0.72978\n",
      "query: risk, certain, computational, approach, c                                                     NDCG@10 0.8527\n",
      "query: markov, supply, hidden, computational, payoff                                                 NDCG@10 0.82593\n",
      "query: finance, value, long, average, business                                                       NDCG@10 0.57218\n",
      "query: financial, spark, science, focus, search                                                      NDCG@10 0.5556\n",
      "query: supply, notebook, fundamental, know, basic                                                    NDCG@10 0.81872\n",
      "query: r, linear, ethereum, c, machine                                                               NDCG@10 1.0\n",
      "query: science, future, problem, demand, pytorch                                                     NDCG@10 0.80527\n",
      "query: r, ec, kera, opponent, model                                                                  NDCG@10 0.87602\n",
      "query: markov, descent, algebra, math, research                                                      NDCG@10 0.97762\n",
      "query: clojurescript, ai, analysis, background, science                                              NDCG@10 0.84642\n",
      "query: optimisation, opencv, risk, chain, urban                                                      NDCG@10 0.95568\n",
      "query: maing, descent, science, clojurescript, knowledge                                             NDCG@10 0.8841\n",
      "query: schedule, gradient, airport, analysis, system                                                 NDCG@10 0.77461\n",
      "query: logistics, business, strategy, analytics, math                                                NDCG@10 0.88691\n",
      "query: program, future, kera, ec, concept                                                            NDCG@10 0.71152\n",
      "Average NDCG@10 for model 2: 0.73971\n",
      "########################################################################################################################################################################################################\n",
      "Calculating NDCCG for Model 3 Cosine Similarity (with query expansion, with course information data and 50% of survey data)\n",
      "\n",
      "Current computing Query: network, term, model, technology, probability\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: term, different, skill, mongodb, long\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: logistics, analysis, operation, basic, r\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: esd, network, evaluate, program, r\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: operation, basic, evaluation, price, evaluate\n",
      "Number of terms in corpus: 14\n",
      "\n",
      "Current computing Query: infrastructure, metric, pytorch, model, client\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: approach, logistics, shag, infrastructure, equity\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: data, sql, different, analytics, model\n",
      "Number of terms in corpus: 11\n",
      "\n",
      "Current computing Query: computational, best, server, certain, ec\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: sklearn, metric, demand, schedule, fundamental\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: digitalisation, skill, long, technology, aviation\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: r, hidden, artificial, schedule, simulate\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: optimisation, decision, risk, aws, jupyter\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: decentralizedapp, equity, math, ethereum, technology\n",
      "Number of terms in corpus: 6\n",
      "\n",
      "Current computing Query: financial, value, metric, optimize, analysis\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: risk, certain, computational, approach, c\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: markov, supply, hidden, computational, payoff\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: finance, value, long, average, business\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: financial, spark, science, focus, search\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: supply, notebook, fundamental, know, basic\n",
      "Number of terms in corpus: 10\n",
      "\n",
      "Current computing Query: r, linear, ethereum, c, machine\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: science, future, problem, demand, pytorch\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: r, ec, kera, opponent, model\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: markov, descent, algebra, math, research\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: clojurescript, ai, analysis, background, science\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: optimisation, opencv, risk, chain, urban\n",
      "Number of terms in corpus: 8\n",
      "\n",
      "Current computing Query: maing, descent, science, clojurescript, knowledge\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: schedule, gradient, airport, analysis, system\n",
      "Number of terms in corpus: 7\n",
      "\n",
      "Current computing Query: logistics, business, strategy, analytics, math\n",
      "Number of terms in corpus: 9\n",
      "\n",
      "Current computing Query: program, future, kera, ec, concept\n",
      "Number of terms in corpus: 7\n",
      "################################\n",
      "average Querying Time: 0.8594570239384969\n",
      "query: network, term, model, technology, probability                                                 NDCG@10 0.41378\n",
      "query: term, different, skill, mongodb, long                                                         NDCG@10 0.53811\n",
      "query: logistics, analysis, operation, basic, r                                                      NDCG@10 0.93147\n",
      "query: esd, network, evaluate, program, r                                                            NDCG@10 0.57294\n",
      "query: operation, basic, evaluation, price, evaluate                                                 NDCG@10 0.51236\n",
      "query: infrastructure, metric, pytorch, model, client                                                NDCG@10 0.33333\n",
      "query: approach, logistics, shag, infrastructure, equity                                             NDCG@10 0.82315\n",
      "query: data, sql, different, analytics, model                                                        NDCG@10 0.97244\n",
      "query: computational, best, server, certain, ec                                                      NDCG@10 0.35621\n",
      "query: sklearn, metric, demand, schedule, fundamental                                                NDCG@10 0.76413\n",
      "query: digitalisation, skill, long, technology, aviation                                             NDCG@10 0.56593\n",
      "query: r, hidden, artificial, schedule, simulate                                                     NDCG@10 0.92731\n",
      "query: optimisation, decision, risk, aws, jupyter                                                    NDCG@10 0.86629\n",
      "query: decentralizedapp, equity, math, ethereum, technology                                          NDCG@10 0.74929\n",
      "query: financial, value, metric, optimize, analysis                                                  NDCG@10 0.76664\n",
      "query: risk, certain, computational, approach, c                                                     NDCG@10 0.87236\n",
      "query: markov, supply, hidden, computational, payoff                                                 NDCG@10 0.8172\n",
      "query: finance, value, long, average, business                                                       NDCG@10 0.72725\n",
      "query: financial, spark, science, focus, search                                                      NDCG@10 0.75404\n",
      "query: supply, notebook, fundamental, know, basic                                                    NDCG@10 0.79306\n",
      "query: r, linear, ethereum, c, machine                                                               NDCG@10 1.0\n",
      "query: science, future, problem, demand, pytorch                                                     NDCG@10 0.59257\n",
      "query: r, ec, kera, opponent, model                                                                  NDCG@10 0.68639\n",
      "query: markov, descent, algebra, math, research                                                      NDCG@10 0.99165\n",
      "query: clojurescript, ai, analysis, background, science                                              NDCG@10 0.85907\n",
      "query: optimisation, opencv, risk, chain, urban                                                      NDCG@10 0.81763\n",
      "query: maing, descent, science, clojurescript, knowledge                                             NDCG@10 0.43068\n",
      "query: schedule, gradient, airport, analysis, system                                                 NDCG@10 0.74383\n",
      "query: logistics, business, strategy, analytics, math                                                NDCG@10 0.96967\n",
      "query: program, future, kera, ec, concept                                                            NDCG@10 0.81329\n",
      "Average NDCG@10 for model 3: 1.03103\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# model 4 5 and 6\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    import pandas as pd\r\n",
    "    if True:\r\n",
    "        ## model 4 BM25 Basic (without query expansion, course information)\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 4 BM25 Basic (without query expansion, course information)')\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        tf = pd.read_csv('../data/course_info_scores/course_info_tf.csv', index_col = 0)\r\n",
    "        tf_norm = pd.read_csv('../data/course_info_scores/course_info_tf_norm.csv', index_col = 0)\r\n",
    "        idf = pd.read_csv('../data/course_info_scores/course_info_idf.csv', header=0, index_col=0)\r\n",
    "        model4NDCG = get_NDCG_BM25BasicNoExpan(query_val,tf,tf_norm,idf)\r\n",
    "        model4NDCGAverage = model4NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model4NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel4.csv')\r\n",
    "        print(\"Average NDCG@10 for model 4: {}\".format(round(model4NDCGAverage.iloc[9],5)))\r\n",
    "        print('\\n')\r\n",
    "        \r\n",
    "        ## model 5 BM25 Basic (query expansion, course information)\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 5 BM25 Basic (query expansion, course information)')\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        tf = pd.read_csv('../data/course_info_scores/course_info_tf.csv', index_col = 0)\r\n",
    "        tf_norm = pd.read_csv('../data/course_info_scores/course_info_tf_norm.csv', index_col = 0)\r\n",
    "        idf = pd.read_csv('../data/course_info_scores/course_info_idf.csv', header=0, index_col=0)\r\n",
    "        model5NDCG = get_NDCG_BM25Basic(query_val,tf,tf_norm,idf)\r\n",
    "        model5NDCGAverage = model5NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model5NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel5.csv')\r\n",
    "        print(\"Average NDCG@10 for model 5: {}\".format(round(model5NDCGAverage.iloc[9],5)))\r\n",
    "        print('\\n')\r\n",
    "        \r\n",
    "        ## model 6 BM25 Basic (query expansion, course information + survey (50%))\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 6 BM25 Basic (query expansion, course information + survey (50%))')\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        tf = pd.read_csv('../data/course_info_with_survey_scores/course_info_with_survey_tf.csv', index_col = 0)\r\n",
    "        tf_norm = pd.read_csv('../data/course_info_with_survey_scores/course_info_with_survey_tf_norm.csv', index_col = 0)\r\n",
    "        idf = pd.read_csv('../data/course_info_with_survey_scores/course_info_with_survey_idf.csv', header=0, index_col=0)\r\n",
    "        model6NDCG = get_NDCG_BM25Basic(query_val,tf,tf_norm,idf)\r\n",
    "        model6NDCGAverage = model6NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model6NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel6.csv')\r\n",
    "        print(\"Average NDCG@10 for model 6: {}\".format(round(model6NDCGAverage.iloc[9],5)))\r\n",
    "        print('\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "########################################################################################################################################################################################################\n",
      "Calculating NDCCG for Model 4 BM25 Basic (without query expansion, course information)\n",
      "query: network, term, model, technology, probability                                                 NDCG@10 0.63733\n",
      "query: term, different, skill, mongodb, long                                                         NDCG@10 0.3003\n",
      "query: logistics, analysis, operation, basic, r                                                      NDCG@10 0.64478\n",
      "query: esd, network, evaluate, program, r                                                            NDCG@10 0.68379\n",
      "query: operation, basic, evaluation, price, evaluate                                                 NDCG@10 0.30771\n",
      "query: infrastructure, metric, pytorch, model, client                                                NDCG@10 0.75553\n",
      "query: approach, logistics, shag, infrastructure, equity                                             NDCG@10 1.0\n",
      "query: data, sql, different, analytics, model                                                        NDCG@10 0.83945\n",
      "query: computational, best, server, certain, ec                                                      NDCG@10 1.0\n",
      "query: sklearn, metric, demand, schedule, fundamental                                                NDCG@10 0.92565\n",
      "query: digitalisation, skill, long, technology, aviation                                             NDCG@10 0.47804\n",
      "query: r, hidden, artificial, schedule, simulate                                                     NDCG@10 0.93868\n",
      "query: optimisation, decision, risk, aws, jupyter                                                    NDCG@10 0.82906\n",
      "query: decentralizedapp, equity, math, ethereum, technology                                          NDCG@10 0.97009\n",
      "query: financial, value, metric, optimize, analysis                                                  NDCG@10 0.93213\n",
      "query: risk, certain, computational, approach, c                                                     NDCG@10 0.61049\n",
      "query: markov, supply, hidden, computational, payoff                                                 NDCG@10 0.83712\n",
      "query: finance, value, long, average, business                                                       NDCG@10 1.0\n",
      "query: financial, spark, science, focus, search                                                      NDCG@10 0.7571\n",
      "query: supply, notebook, fundamental, know, basic                                                    NDCG@10 0.89718\n",
      "query: r, linear, ethereum, c, machine                                                               NDCG@10 1.0\n",
      "query: science, future, problem, demand, pytorch                                                     NDCG@10 0.78679\n",
      "query: r, ec, kera, opponent, model                                                                  NDCG@10 0.57317\n",
      "query: markov, descent, algebra, math, research                                                      NDCG@10 0.96004\n",
      "query: clojurescript, ai, analysis, background, science                                              NDCG@10 0.81191\n",
      "query: optimisation, opencv, risk, chain, urban                                                      NDCG@10 0.92182\n",
      "query: maing, descent, science, clojurescript, knowledge                                             NDCG@10 0.90692\n",
      "query: schedule, gradient, airport, analysis, system                                                 NDCG@10 0.97484\n",
      "query: logistics, business, strategy, analytics, math                                                NDCG@10 0.98233\n",
      "query: program, future, kera, ec, concept                                                            NDCG@10 0.88052\n",
      "Average Time for 30 number of queries : 0.011734342575073243\n",
      "Average NDCG@10 for model 4: 0.80476\n",
      "\n",
      "\n",
      "########################################################################################################################################################################################################\n",
      "Calculating NDCCG for Model 5 BM25 Basic (query expansion, course information)\n",
      "query: network, term, model, technology, probability                                                 NDCG@10 0.57785\n",
      "query: term, different, skill, mongodb, long                                                         NDCG@10 0.12155\n",
      "query: logistics, analysis, operation, basic, r                                                      NDCG@10 0.56729\n",
      "query: esd, network, evaluate, program, r                                                            NDCG@10 0.66837\n",
      "query: operation, basic, evaluation, price, evaluate                                                 NDCG@10 0.21113\n",
      "query: infrastructure, metric, pytorch, model, client                                                NDCG@10 0.59612\n",
      "query: approach, logistics, shag, infrastructure, equity                                             NDCG@10 0.80461\n",
      "query: data, sql, different, analytics, model                                                        NDCG@10 0.8515\n",
      "query: computational, best, server, certain, ec                                                      NDCG@10 0.30557\n",
      "query: sklearn, metric, demand, schedule, fundamental                                                NDCG@10 0.79454\n",
      "query: digitalisation, skill, long, technology, aviation                                             NDCG@10 0.70168\n",
      "query: r, hidden, artificial, schedule, simulate                                                     NDCG@10 0.92157\n",
      "query: optimisation, decision, risk, aws, jupyter                                                    NDCG@10 0.8334\n",
      "query: decentralizedapp, equity, math, ethereum, technology                                          NDCG@10 0.98862\n",
      "query: financial, value, metric, optimize, analysis                                                  NDCG@10 0.88277\n",
      "query: risk, certain, computational, approach, c                                                     NDCG@10 0.70366\n",
      "query: markov, supply, hidden, computational, payoff                                                 NDCG@10 0.89938\n",
      "query: finance, value, long, average, business                                                       NDCG@10 0.70384\n",
      "query: financial, spark, science, focus, search                                                      NDCG@10 0.47446\n",
      "query: supply, notebook, fundamental, know, basic                                                    NDCG@10 0.75296\n",
      "query: r, linear, ethereum, c, machine                                                               NDCG@10 1.0\n",
      "query: science, future, problem, demand, pytorch                                                     NDCG@10 0.73551\n",
      "query: r, ec, kera, opponent, model                                                                  NDCG@10 0.7489\n",
      "query: markov, descent, algebra, math, research                                                      NDCG@10 0.97928\n",
      "query: clojurescript, ai, analysis, background, science                                              NDCG@10 0.72483\n",
      "query: optimisation, opencv, risk, chain, urban                                                      NDCG@10 0.91006\n",
      "query: maing, descent, science, clojurescript, knowledge                                             NDCG@10 0.86038\n",
      "query: schedule, gradient, airport, analysis, system                                                 NDCG@10 0.92173\n",
      "query: logistics, business, strategy, analytics, math                                                NDCG@10 0.93913\n",
      "query: program, future, kera, ec, concept                                                            NDCG@10 0.7001\n",
      "Average Time for 30 number of queries : 0.032047541936238606\n",
      "Average NDCG@10 for model 5: 0.72936\n",
      "\n",
      "\n",
      "########################################################################################################################################################################################################\n",
      "Calculating NDCCG for Model 6 BM25 Basic (query expansion, course information + survey (50%))\n",
      "query: network, term, model, technology, probability                                                 NDCG@10 0.62827\n",
      "query: term, different, skill, mongodb, long                                                         NDCG@10 0.43588\n",
      "query: logistics, analysis, operation, basic, r                                                      NDCG@10 0.77423\n",
      "query: esd, network, evaluate, program, r                                                            NDCG@10 0.82501\n",
      "query: operation, basic, evaluation, price, evaluate                                                 NDCG@10 0.42692\n",
      "query: infrastructure, metric, pytorch, model, client                                                NDCG@10 0.54151\n",
      "query: approach, logistics, shag, infrastructure, equity                                             NDCG@10 0.79053\n",
      "query: data, sql, different, analytics, model                                                        NDCG@10 0.64661\n",
      "query: computational, best, server, certain, ec                                                      NDCG@10 0.21801\n",
      "query: sklearn, metric, demand, schedule, fundamental                                                NDCG@10 0.8232\n",
      "query: digitalisation, skill, long, technology, aviation                                             NDCG@10 0.72501\n",
      "query: r, hidden, artificial, schedule, simulate                                                     NDCG@10 0.92876\n",
      "query: optimisation, decision, risk, aws, jupyter                                                    NDCG@10 0.80224\n",
      "query: decentralizedapp, equity, math, ethereum, technology                                          NDCG@10 0.96178\n",
      "query: financial, value, metric, optimize, analysis                                                  NDCG@10 0.84402\n",
      "query: risk, certain, computational, approach, c                                                     NDCG@10 0.72426\n",
      "query: markov, supply, hidden, computational, payoff                                                 NDCG@10 0.9001\n",
      "query: finance, value, long, average, business                                                       NDCG@10 0.53065\n",
      "query: financial, spark, science, focus, search                                                      NDCG@10 0.4893\n",
      "query: supply, notebook, fundamental, know, basic                                                    NDCG@10 0.82859\n",
      "query: r, linear, ethereum, c, machine                                                               NDCG@10 0.95993\n",
      "query: science, future, problem, demand, pytorch                                                     NDCG@10 0.34092\n",
      "query: r, ec, kera, opponent, model                                                                  NDCG@10 0.81978\n",
      "query: markov, descent, algebra, math, research                                                      NDCG@10 0.97175\n",
      "query: clojurescript, ai, analysis, background, science                                              NDCG@10 0.52125\n",
      "query: optimisation, opencv, risk, chain, urban                                                      NDCG@10 0.79368\n",
      "query: maing, descent, science, clojurescript, knowledge                                             NDCG@10 0.3098\n",
      "query: schedule, gradient, airport, analysis, system                                                 NDCG@10 0.94641\n",
      "query: logistics, business, strategy, analytics, math                                                NDCG@10 0.83859\n",
      "query: program, future, kera, ec, concept                                                            NDCG@10 0.873\n",
      "Average Time for 30 number of queries : 0.03740061124165853\n",
      "Average NDCG@10 for model 6: 0.70733\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    import pandas as pd\r\n",
    "    if True:\r\n",
    "        ## to create the function to obtain the NDCG for model 7 and 8\r\n",
    "        ## model 7 Bm25 with Reformulation (query expansion, course information + survey (50%))\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 7 Bm25 with Reformulation (query expansion, course information + survey (50%))')\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        tf = pd.read_csv('../data/trained_scores/course_info_with_survey_tf_trained.csv', index_col = 0)\r\n",
    "        tf_norm = pd.read_csv('../data/trained_scores/course_info_with_survey_tf_norm_trained.csv', index_col = 0)\r\n",
    "        idf = pd.read_csv('../data/trained_scores/course_info_with_survey_idf_trained.csv', header=0, index_col=0)\r\n",
    "        model7NDCG = get_NDCG_BM25Basic(query_val,tf,tf_norm,idf)\r\n",
    "        model7NDCGAverage = model7NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model7NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel7.csv')\r\n",
    "        print(\"Average NDCG@10 for model 7: {}\".format(round(model7NDCGAverage.iloc[9],5)))\r\n",
    "        print('\\n')\r\n",
    "        \r\n",
    "        ## model 8 Bm25 with Reformulation and Pseudo Relevance Feedback (query expansion, course information + survey (50%))\r\n",
    "        print(\"#\"*200)\r\n",
    "        print('Calculating NDCCG for Model 8 Bm25 with Reformulation and Pseudo Relevance Feedback (query expansion, course information + survey (50%))')\r\n",
    "        query_val= pd.read_csv('../data/survey/vaildation_sample_query.csv',index_col = 0)\r\n",
    "        tf = pd.read_csv('../data/trained_scores/course_info_with_survey_tf_trained.csv', index_col = 0)\r\n",
    "        tf_norm = pd.read_csv('../data/trained_scores/course_info_with_survey_tf_norm_trained.csv', index_col = 0)\r\n",
    "        idf = pd.read_csv('../data/trained_scores/course_info_with_survey_idf_trained.csv', header=0, index_col=0)\r\n",
    "        model8NDCG = get_NDCG_BM25WPseudo(query_val,tf,tf_norm,idf)    \r\n",
    "        model8NDCGAverage = model8NDCG.iloc[:, 1:].mean(axis=1)\r\n",
    "        # model8NDCGAverage.to_csv('../results/ndcg_score/ndcg_score_mdoel8.csv')\r\n",
    "        print(\"Average NDCG@10 for model 8: {}\".format(round(model8NDCGAverage.iloc[9],5)))\r\n",
    "    print('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}