{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## The purpose of the script\n",
    "This script is to convert the text from the suvery into word from suvery to modules \n",
    "<br>\n",
    "This is to merge 50% of the suvery to training dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from os import path\r\n",
    "## inorder to obtain the relative file path\r\n",
    "## https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python \r\n",
    "## ../ refer to looking into the folder above\r\n",
    "relativePath = path.relpath(\"../../data/survey/CustomerFeedback(Responses).xlsx\")\r\n",
    "## require the engine = 'openpyxl' to read the xlsx\r\n",
    "df = pd.read_excel(relativePath, index_col = 0,engine=\"openpyxl\")\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## data cleaning\r\n",
    "## drop from column\r\n",
    "df.dropna(axis= 1, how = 'all', inplace= True)\r\n",
    "## drop from row\r\n",
    "df.dropna(axis= 0, how = 'all', inplace= True)\r\n",
    "## replace column value to 1 if 'Check if taken' or ' Check if taken or taking during Term 6 to 8'\r\n",
    "df.replace('Check if taken', 1, inplace = True)\r\n",
    "df.replace('Check if taken or taking during Term 6 to 8', 1, inplace = True)\r\n",
    "df.describe(include ='all')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "random.seed(123)\r\n",
    "suveryMerge = df.sample(frac=0.5,random_state=200) #random state is a seed value\r\n",
    "suveryFeedbackNValid= df.drop(suveryMerge.index)\r\n",
    "suveryFeedback= suveryFeedbackNValid.sample(frac=0.5,random_state=200)\r\n",
    "suveryVaild= suveryFeedbackNValid.drop(suveryFeedback.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "suveryMerge.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Formatting the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def obtainingElectives(_df):\r\n",
    "    print('Starting to obtain dict of electives')\r\n",
    "    electiveDict = {}\r\n",
    "    for columnName in _df.columns:\r\n",
    "        if 'Elective Modules taken or taking' in columnName:\r\n",
    "            openSquareBracket = columnName.find('[') + 1\r\n",
    "            closeSquareBracket = columnName.find(']')\r\n",
    "            electiveDict[columnName] = columnName[openSquareBracket:closeSquareBracket]\r\n",
    "    return(electiveDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def updatingdict(_df,electiveWordsDict,key):\r\n",
    "    key = str(key)\r\n",
    "    ## if there is no word in columnname\r\n",
    "    if key not in electiveWordsDict.keys():\r\n",
    "        electiveWordsDict[key] = len(_df)\r\n",
    "    else:\r\n",
    "        electiveWordsDict[key] = electiveWordsDict[key] + len(_df)\r\n",
    "    return(electiveWordsDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def obtainingDetailsFromPillar(_df,electiveWordsDict,columnOfInterest):\r\n",
    "    ## filtering the _df\r\n",
    "    pillarDf = _df.copy(deep = False)\r\n",
    "    print('Obtaining from \"{}\" column'.format(columnOfInterest))\r\n",
    "    ## number of times the word/skills appears\r\n",
    "    for pillar in pillarDf[columnOfInterest].unique():\r\n",
    "        singlePillarDf = pillarDf[pillarDf[columnOfInterest] == pillar]\r\n",
    "        electiveWordsDict =  updatingdict(singlePillarDf,electiveWordsDict,pillar)\r\n",
    "    return(electiveWordsDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def obtainingDetailsFromTrack(_df,electiveWordsDict,columnOfInterest):\r\n",
    "    print('Obtaining from \"{}\" column'.format(columnOfInterest))\r\n",
    "    for columnName in _df.columns:\r\n",
    "    ## ensure a part of the columns name contains the columnOfInterest\r\n",
    "        if columnOfInterest in columnName:\r\n",
    "    ## filtered df\r\n",
    "            singleTrackDf = _df[_df[columnName] == 1]\r\n",
    "    ## finding the index of []\r\n",
    "            openSquareBracket = columnName.find('[') + 1\r\n",
    "            closeSquareBracket = columnName.find(']')\r\n",
    "    ## if the columnName does not have bracket then do not shorten the columnName\r\n",
    "            if (openSquareBracket > 0) & (closeSquareBracket > 0):\r\n",
    "                columnName = columnName[openSquareBracket:closeSquareBracket]\r\n",
    "    ## number of times the word/skills appears\r\n",
    "            electiveWordsDict =  updatingdict(singleTrackDf,electiveWordsDict,columnName)\r\n",
    "    return(electiveWordsDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def textCleaning(s):\r\n",
    "    ## spacy tutorial https://www.analyticsvidhya.com/blog/2020/03/spacy-tutorial-learn-natural-language-processing/\r\n",
    "\r\n",
    "    import json\r\n",
    "    import string\r\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "    import pandas as pd\r\n",
    "    from gensim.parsing.preprocessing import remove_stopwords\r\n",
    "    import nltk\r\n",
    "    from nltk.stem import WordNetLemmatizer\r\n",
    "    from nltk.corpus import wordnet\r\n",
    "    import numpy as np\r\n",
    "\r\n",
    "    lemmatizer = WordNetLemmatizer()\r\n",
    "    def get_wordnet_pos(word):\r\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\r\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\r\n",
    "                    \"N\": wordnet.NOUN,\r\n",
    "                    \"V\": wordnet.VERB,\r\n",
    "                    \"R\": wordnet.ADV}\r\n",
    "\r\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\r\n",
    "\r\n",
    "    s = str(np.char.lower(s))\r\n",
    "    s = ''.join([i for i in s if not i.isdigit()])\r\n",
    "    s = remove_stopwords(s)\r\n",
    "    s = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(s)]\r\n",
    "    s = ' '.join([str(elem) for elem in s])\r\n",
    "    s = s.translate(str.maketrans('','',string.punctuation))\r\n",
    "    s = s.split()\r\n",
    "    return(s)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def obtainingDetailsFromNonNumericalColumnOfInterest(_df,electiveWordsDict,columnOfInterest):\r\n",
    "    print('Obtaining from \"{}\" column'.format(columnOfInterest))\r\n",
    "    ## filter by those elective or columns which shows skills or interest\r\n",
    "    df = _df.copy(deep = False)\r\n",
    "    df = df[columnOfInterest]\r\n",
    "    df.dropna(axis= 0, how = 'all', inplace= True)\r\n",
    "    for skillOrInterest in df:\r\n",
    "        skillOrInterest = textCleaning(skillOrInterest)\r\n",
    "        print(skillOrInterest)\r\n",
    "    ## number of times the word/skills appears\r\n",
    "    ## just use a df of length 1 as we are checking one row of entry at a time\r\n",
    "        dfOfLength1 = df.head(1)\r\n",
    "        for word in skillOrInterest:\r\n",
    "            electiveWordsDict = updatingdict(dfOfLength1,electiveWordsDict,word)\r\n",
    "    return(electiveWordsDict) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def formattingSurveyData(_df):\r\n",
    "    df = _df.copy(deep = False)\r\n",
    "    ## obtainig electives names from suvery\r\n",
    "    electiveDict = obtainingElectives(df)\r\n",
    "    ## dict to store the words from suvery about all elective\r\n",
    "    allElectiveDict = {}\r\n",
    "    ## iterate through the electives\r\n",
    "    for k,v in electiveDict.items():\r\n",
    "    ## filter by electives\r\n",
    "        electiveDf = df[df[k] == 1]\r\n",
    "    ## dict to store the words from suvery about all elective\r\n",
    "        electiveWordsDict = {}\r\n",
    "        print('\\n')\r\n",
    "    ## check the pillar, focus track, skills, interest and knowledge gain that are remaining after filtering\r\n",
    "    ## count the occurances of them happening\r\n",
    "    ## convert the those into words to be index of the rows (including elective name)\r\n",
    "        pillar = obtainingDetailsFromPillar(electiveDf,electiveWordsDict,'Pillar')\r\n",
    "        focusTrack = obtainingDetailsFromTrack(electiveDf,electiveWordsDict,'Focus Track')\r\n",
    "        skillsFromEachElective = obtainingDetailsFromNonNumericalColumnOfInterest(electiveDf,electiveWordsDict,v)\r\n",
    "    ## add to the overall\r\n",
    "        allElectiveDict[v] = electiveWordsDict\r\n",
    "    return(allElectiveDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "formattingSurveyDataDict = formattingSurveyData(suveryMerge)\r\n",
    "formattingSurveyDataDict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def formattingTable(_dict):\r\n",
    "    import pandas as pd\r\n",
    "    wordDf = pd.DataFrame()\r\n",
    "    for k,v in _dict.items():\r\n",
    "        for k2,v2 in v.items():\r\n",
    "            wordDf.at[ k2 ,k ] = v2\r\n",
    "    wordDf.fillna(0, inplace = True)\r\n",
    "\r\n",
    "    return(wordDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "formattingTableDf = formattingTable(formattingSurveyDataDict)\r\n",
    "formattingTableDf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "formattingTableDf.to_csv('../../data/survey/survey_for_merging_converted.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning the the index words\r\n",
    "<br> don't use the function below, there are some faults with the code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "dict={}\r\n",
    "for column in formattingTableDf.columns[1:]:\r\n",
    "    # print(column)\r\n",
    "    dict[column]=[]\r\n",
    "    for index,row in formattingTableDf.iterrows():\r\n",
    "        text = index\r\n",
    "        text = str(np.char.lower(text))\r\n",
    "        text = re.sub(r'[^\\w]', ' ', text)\r\n",
    "        text = re.sub(' +', ' ', text)\r\n",
    "        text = remove_stopwords(text)\r\n",
    "        text = text.split(' ')\r\n",
    "        for i in range(int(row[column])):\r\n",
    "            for word in text:\r\n",
    "                dict[column].append(word)\r\n",
    "\r\n",
    "# adding more weight by doubling the relevant word counts for each course\r\n",
    "for i,j in dict.items():\r\n",
    "    dict[i] = j*2\r\n",
    "\r\n",
    "with open('../../data/survey/merged_survey.json','w') as file:\r\n",
    "    json.dump(dict, file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}