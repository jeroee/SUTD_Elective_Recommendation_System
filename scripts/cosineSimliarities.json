{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\"\"\"[summary]\n",
    "The script is to compute the cosine simliarities between queries and the document\n",
    "The steps are as follows:\n",
    "1. read the tf file\n",
    "2. obtaint the input query\n",
    "3. compute the cosine simliarities between query and each document\n",
    "4.sort by the one with highest simliarity with the highest rank\n",
    "\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[summary]\\nThe script is to compute the cosine simliarities between queries and the document\\nThe steps are as follows:\\n1. read the tf file\\n2. obtaint the input query\\n3. compute the cosine simliarities between query and each document\\n4.sort by the one with highest simliarity with the highest rank\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def readFile(_filePath):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        _filePath ([type]): [description]\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    readFile = pd.read_csv(_filePath,index_col=0)\n",
    "    return(readFile)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
<<<<<<< HEAD
    "def queryVector(query,corpus):\r\n",
    "    \"\"\"[summary]\r\n",
    "    vectorize query based on corpus words\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        query ([list]): [list containing query terms]\r\n",
    "    \"\"\"\r\n",
    "    corpusList = list(corpus.index)\r\n",
    "    ## vector of query with the length of corpusList\r\n",
    "    vector = [0]*len(corpusList)\r\n",
    "    \r\n",
    "    ## format query\r\n",
    "    ## import scripts to process queries\r\n",
    "    import utils.query_processing\r\n",
    "    ## convert to string if not string\r\n",
    "    if type(query) != str:\r\n",
    "        query = ' '.join(query)\r\n",
    "    ## clean the query\r\n",
    "    query = utils.query_processing.process_query(query)\r\n",
    "\r\n",
    "    \"still lacking the query expansion\"\r\n",
    "    \"Need  glove_kv and topn to be saved in the repo\"\r\n",
    "    # query = utils.query_processing.expand_query(query)\r\n",
    "    \r\n",
    "    ## iterate over query terms\r\n",
    "    for wordOfQuery in query:\r\n",
    "    ## variable to tract the corpus index\r\n",
    "        vectorIndex = 0\r\n",
    "    ## iterate over the all corpus and update only if the corpus term in query\r\n",
    "        for wordOfCorpus in corpusList:\r\n",
    "            if wordOfQuery ==  wordOfCorpus:\r\n",
    "                vector[vectorIndex] += 1 \r\n",
    "    ## update corpus index to move onto next word/index\r\n",
    "            vectorIndex += 1               \r\n",
=======
    "def queryVector(query,corpus):\n",
    "    \"\"\"[summary]\n",
    "    vectorize query based on corpus\n",
    "    \n",
    "    Args:\n",
    "        query ([list]): [list containing query terms]\n",
    "    \"\"\"\n",
    "    corpusList = list(corpus.index)\n",
    "    ## vector to track the corpusList\n",
    "    vector = [0]*len(corpusList)\n",
    "    ## iterate over query terms\n",
    "    for wordOfQuery in query:\n",
    "    ## variable to tract the corpus index\n",
    "        vectorIndex = 0\n",
    "    ## iterate over the all corupus\n",
    "        for wordOfCorpus in corpusList:\n",
    "            if wordOfQuery ==  wordOfCorpus:\n",
    "                vector[vectorIndex] += 1 \n",
    "    ## update courpus index\n",
    "            vectorIndex += 1               \n",
>>>>>>> c03ec897d00cc108c483756a4ae82c11b62738c2
    "    return(vector)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
<<<<<<< HEAD
    "def cosineSimilarities(queryVector,docVector):\r\n",
    "    \"\"\"[summary]\r\n",
    "    To compute the cosine similarity of the query with a single column/module in corpus\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        queryVector ([list]): [query]\r\n",
    "        docVector ([list]): [description]\r\n",
    "    \"\"\"\r\n",
    "    from scipy import spatial\r\n",
    "    distance = 1 - spatial.distance.cosine(queryVector, docVector)\r\n",
=======
    "def cosineSimilarities(queryVector,docVector):\n",
    "    from scipy import spatial\n",
    "    distance = 1 - spatial.distance.cosine(queryVector, docVector)\n",
>>>>>>> c03ec897d00cc108c483756a4ae82c11b62738c2
    "    return(round(distance,5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
<<<<<<< HEAD
    "def topModulesForEachQuery(_df, topNumber = 10):\r\n",
    "    \"\"\"[summary]\r\n",
    "    To obtain the top modules for each of the query\r\n",
    "\r\n",
    "    Args:\r\n",
    "        _df ([dataframe]): [description] data with rows of words and columns contain the modules, the cell of the dataframe is the similarity\r\n",
    "    \"\"\"\r\n",
    "    overallTopModules = {}\r\n",
    "    for query in _df.columns:\r\n",
    "        singleModule = {}\r\n",
    "        df.sort_values(by = query,ascending = False, inplace = True)\r\n",
    "        ## obtain top 10 modules\r\n",
    "        topModules = df[query][:topNumber]\r\n",
    "        singleModule['topModules'] = list(topModules.index)\r\n",
    "        singleModule['topModulesScore'] = list(topModules)\r\n",
    "        overallTopModules[str(query)] = (singleModule)\r\n",
    "        \r\n",
    "    import pandas as pd\r\n",
    "    overallTopModulesDf = pd.DataFrame(overallTopModules)\r\n",
=======
    "def topModulesForEachQuery(_df):\n",
    "    overallTopModules = {}\n",
    "    for query in _df.columns:\n",
    "        singleModule = {}\n",
    "        df.sort_values(by = query,ascending = False, inplace = True)\n",
    "        ## obtain top 10 modules\n",
    "        topModules = df[query][:10]\n",
    "        singleModule['topModules'] = list(topModules.index)\n",
    "        singleModule['topModulesScore'] = list(topModules)\n",
    "        overallTopModules[str(query)] = (singleModule)\n",
    "        \n",
    "    import pandas as pd\n",
    "    overallTopModulesDf = pd.DataFrame(overallTopModules)\n",
>>>>>>> c03ec897d00cc108c483756a4ae82c11b62738c2
    "    return(overallTopModulesDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
<<<<<<< HEAD
    "if __name__ == \"__main__\":\r\n",
    "    import pandas as pd\r\n",
    "    \"\"\"\r\n",
    "    Reading the corpus for to formalue the query vector\r\n",
    "    \"\"\"\r\n",
    "    corpus = readFile('../data/course_info_scores/course_info_tf.csv') ## <-- assign the merge corupus here\r\n",
    "    # corpus = readFile('../data/course_info_with_survey_scores/course_info_with_survey_tf.csv') ## <-- assign the merge corupus here\r\n",
    "    \r\n",
    "    \r\n",
    "    ## vaildation set\r\n",
    "    \"\"\"[summary]\r\n",
    "    U can contorl which vaildation set to choose to test the cosine similarity model\r\n",
    "    True : would be for the testingQuery that is self create which ensure a value when computing cosineSimilarities\r\n",
    "    False : obtain the query based on 50% of vaildation dataset which might have all cosine similarities of zero\r\n",
    "    \"\"\"\r\n",
    "    if True:\r\n",
    "        testingQuery1 = ['ability','able','abstract']\r\n",
    "        testingQuery2 = ['abstraction','accommodate','accompanies']\r\n",
    "        testingQuery3 = ['account','accounting','achieve']\r\n",
    "        testingQueryList = [[testingQuery1],[testingQuery2],[testingQuery3]]\r\n",
    "        testingQueryDf = pd.DataFrame.from_records(testingQueryList,columns = ['querySample'])\r\n",
    "        queries = testingQueryDf\r\n",
    "        \r\n",
    "    else:\r\n",
    "        vaildationQueries = readFile('../data/survey/vaildation_sample_query.csv')\r\n",
    "        queries = vaildationQueries\r\n",
    "    \r\n",
    "    ## iterate over the vaildationQueries\r\n",
    "    queriesScore = {}\r\n",
    "    for row,query in queries.T.iteritems():\r\n",
    "        print('\\nCurrent computing Query: {}'.format(query['querySample']))\r\n",
    "    ## computing a single query vector\r\n",
    "        singleQueryVector = queryVector(query['querySample'],corpus)\r\n",
    "        print(\"Number of terms in corpus: {}\".format(sum(singleQueryVector)))\r\n",
    "    \r\n",
    "    ## computing the cosine similarities scores by comparing the query vector with every modules' vector\r\n",
    "    ## list to save the cosine similarities for every module that the query is compared against\r\n",
    "        CosineSimilaritiesScore = []\r\n",
    "        for modules in list(corpus):\r\n",
    "            SimilaritiesScore = cosineSimilarities(singleQueryVector,corpus[modules])\r\n",
    "            CosineSimilaritiesScore.append(SimilaritiesScore)\r\n",
    "            # print(\"Score for Query on {} : {}\".format(modules,SimilaritiesScore))\r\n",
    "        queriesScore[str(query['querySample'])] = CosineSimilaritiesScore\r\n",
    "        \r\n",
    "    ## Convert to dict({query : cosineSimilaritiesScore}) to df\r\n",
    "    modules = list(corpus)\r\n",
    "    df  = pd.DataFrame.from_dict(queriesScore,orient='index',columns=modules)\r\n",
    "    ## this df.T is required as I would want to convert inital df's indexs are words and the columns are modules\r\n",
    "    df = df.T\r\n",
    "    \r\n",
    "    ##obtaining top 10 modules for each query\r\n",
    "    rankedModule = topModulesForEachQuery(df)\r\n",
    "    rankedModule\r\n"
=======
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    corpus = readFile('../data/trained_scores/.csv') ## <-- assign the merge corupus here tf\n",
    "    \n",
    "    ## vaildation set\n",
    "    \"\"\"[summary]\n",
    "    U can contorl which vaildation set to choose to test the cosine similarity model\n",
    "    True : would be for the testingQuery that is self create which ensure a value when computing cosineSimilarities\n",
    "    False : obtain the query based on 50% of vaildation dataset which might have all cosine similarities of zero\n",
    "    \"\"\"\n",
    "    if False:\n",
    "        testingQuery1 = ['ability','able','abstract']\n",
    "        testingQuery2 = ['abstraction','accommodate','accompanies']\n",
    "        testingQuery3 = ['account','accounting','achieve']\n",
    "        testingQueryList = [[testingQuery1],[testingQuery2],[testingQuery3]]\n",
    "        testingQueryDf = pd.DataFrame.from_records(testingQueryList,columns = ['querySample'])\n",
    "        queries = testingQueryDf\n",
    "        \n",
    "    else:\n",
    "        vaildationQueries = readFile('../data/survey/vaildation_sample_query.csv')\n",
    "        queries = vaildationQueries\n",
    "    \n",
    "    ## iterate over the vaildationQueries\n",
    "    queriesScore = {}\n",
    "    for row,query in queries.T.iteritems():\n",
    "        print('\\nCurrent computing Query: {}'.format(query['querySample']))\n",
    "        singleQueryVector = queryVector(query['querySample'],corpus)\n",
    "        print(\"Number of terms in corpus: {}\".format(sum(singleQueryVector)))\n",
    "        \n",
    "        CosineSimilaritiesScore = []\n",
    "        for modules in list(corpus):\n",
    "            SimilaritiesScore = cosineSimilarities(singleQueryVector,corpus[modules])\n",
    "            CosineSimilaritiesScore.append(SimilaritiesScore)\n",
    "            # print(\"Score for Query on {} : {}\".format(modules,SimilaritiesScore))\n",
    "        queriesScore[str(query['querySample'])] = CosineSimilaritiesScore\n",
    "        \n",
    "    ## Convert to dict to df\n",
    "    modules = list(corpus)\n",
    "    df  = pd.DataFrame.from_dict(queriesScore,orient='index',columns=modules)\n",
    "    df = df.T\n",
    "    \n",
    "    ##obtaining top modules for each query\n",
    "    rankedModule = topModulesForEachQuery(df)\n",
    "    rankedModule\n"
>>>>>>> c03ec897d00cc108c483756a4ae82c11b62738c2
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Current computing Query: ['ability', 'able', 'abstract']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "expand_query() missing 2 required positional arguments: 'glove_kv' and 'topn'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-62b1c20802ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nCurrent computing Query: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'querySample'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m## computing a single query vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0msingleQueryVector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueryVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'querySample'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of terms in corpus: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingleQueryVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-b771b0bc1d3a>\u001b[0m in \u001b[0;36mqueryVector\u001b[1;34m(query, corpus)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;34m\"still lacking the query expansion\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_processing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m## iterate over query terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expand_query() missing 2 required positional arguments: 'glove_kv' and 'topn'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    import pandas as pd\r\n",
    "    \"\"\"\r\n",
    "    Reading the corpus for to formalue the query vector\r\n",
    "    \"\"\"\r\n",
    "    corpus = readFile('../data/course_info_scores/course_info_tf.csv') ## <-- assign the merge corupus here\r\n",
    "    # corpus = readFile('../data/course_info_with_survey_scores/course_info_with_survey_tf.csv') ## <-- assign the merge corupus here\r\n",
    "    \r\n",
    "    \r\n",
    "    ## vaildation set\r\n",
    "    \"\"\"[summary]\r\n",
    "    U can contorl which vaildation set to choose to test the cosine similarity model\r\n",
    "    True : would be for the testingQuery that is self create which ensure a value when computing cosineSimilarities\r\n",
    "    False : obtain the query based on 50% of vaildation dataset which might have all cosine similarities of zero\r\n",
    "    \"\"\"\r\n",
    "    if True:\r\n",
    "        testingQuery1 = ['ability','able','abstract']\r\n",
    "        testingQuery2 = ['abstraction','accommodate','accompanies']\r\n",
    "        testingQuery3 = ['account','accounting','achieve']\r\n",
    "        testingQueryList = [[testingQuery1],[testingQuery2],[testingQuery3]]\r\n",
    "        testingQueryDf = pd.DataFrame.from_records(testingQueryList,columns = ['querySample'])\r\n",
    "        queries = testingQueryDf\r\n",
    "        \r\n",
    "    else:\r\n",
    "        vaildationQueries = readFile('../data/survey/vaildation_sample_query.csv')\r\n",
    "        queries = vaildationQueries\r\n",
    "    \r\n",
    "    ## iterate over the vaildationQueries\r\n",
    "    queriesScore = {}\r\n",
    "    for row,query in queries.T.iteritems():\r\n",
    "        print('\\nCurrent computing Query: {}'.format(query['querySample']))\r\n",
    "    ## computing a single query vector\r\n",
    "        singleQueryVector = queryVector(query['querySample'],corpus)\r\n",
    "        print(\"Number of terms in corpus: {}\".format(sum(singleQueryVector)))\r\n",
    "    \r\n",
    "    ## computing the cosine similarities scores by comparing the query vector with every modules' vector\r\n",
    "    ## list to save the cosine similarities for every module that the query is compared against\r\n",
    "        CosineSimilaritiesScore = []\r\n",
    "        for modules in list(corpus):\r\n",
    "            SimilaritiesScore = cosineSimilarities(singleQueryVector,corpus[modules])\r\n",
    "            CosineSimilaritiesScore.append(SimilaritiesScore)\r\n",
    "            # print(\"Score for Query on {} : {}\".format(modules,SimilaritiesScore))\r\n",
    "        queriesScore[str(query['querySample'])] = CosineSimilaritiesScore\r\n",
    "        \r\n",
    "    ## Convert to dict({query : cosineSimilaritiesScore}) to df\r\n",
    "    modules = list(corpus)\r\n",
    "    df  = pd.DataFrame.from_dict(queriesScore,orient='index',columns=modules)\r\n",
    "    ## this df.T is required as I would want to convert inital df's indexs are words and the columns are modules\r\n",
    "    df = df.T\r\n",
    "    \r\n",
    "    ##obtaining top 10 modules for each query\r\n",
    "    rankedModule = topModulesForEachQuery(df)\r\n",
    "    rankedModule\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Current computing Query: ['ability', 'able', 'abstract']\n",
      "['ability', 'able', 'abstract']\n",
      "Number of terms in corpus: 3\n",
      "\n",
      "Current computing Query: ['abstraction', 'accommodate', 'accompanies']\n",
      "['abstraction', 'accommodate', 'accompanies']\n",
      "Number of terms in corpus: 3\n",
      "\n",
      "Current computing Query: ['account', 'accounting', 'achieve']\n",
      "['account', 'accounting', 'achieve']\n",
      "Number of terms in corpus: 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rankedModule"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   ['ability', 'able', 'abstract']  \\\n",
       "topModules       [50.021 Artificial Intelligence, 50.039 Theory...   \n",
       "topModulesScore  [0.14718, 0.11448, 0.06792, 0.05243, 0.03748, ...   \n",
       "\n",
       "                     ['abstraction', 'accommodate', 'accompanies']  \\\n",
       "topModules       [40.320 Airport Systems Planning and Design, 5...   \n",
       "topModulesScore  [0.02817, 0.01944, 0.01902, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                              ['account', 'accounting', 'achieve']  \n",
       "topModules       [40.324 Fundamentals of Investing, 40.320 Airp...  \n",
       "topModulesScore  [0.07865, 0.02817, 0.0268, 0.0, 0.0, 0.0, 0.0,...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>['ability', 'able', 'abstract']</th>\n",
       "      <th>['abstraction', 'accommodate', 'accompanies']</th>\n",
       "      <th>['account', 'accounting', 'achieve']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topModules</th>\n",
       "      <td>[50.021 Artificial Intelligence, 50.039 Theory...</td>\n",
       "      <td>[40.320 Airport Systems Planning and Design, 5...</td>\n",
       "      <td>[40.324 Fundamentals of Investing, 40.320 Airp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topModulesScore</th>\n",
       "      <td>[0.14718, 0.11448, 0.06792, 0.05243, 0.03748, ...</td>\n",
       "      <td>[0.02817, 0.01944, 0.01902, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.07865, 0.02817, 0.0268, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}