{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\"\"\"[summary]\r\n",
    "The script is to compute the cosine simliarities between queries and the document\r\n",
    "The steps are as follows:\r\n",
    "1. read the tf file\r\n",
    "2. obtaint the input query\r\n",
    "3. compute the cosine simliarities between query and each document\r\n",
    "4.sort by the one with highest simliarity with the highest rank\r\n",
    "\r\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[summary]\\nThe script is to compute the cosine simliarities between queries and the document\\nThe steps are as follows:\\n1. read the tf file\\n2. obtaint the input query\\n3. compute the cosine simliarities between query and each document\\n4.sort by the one with highest simliarity with the highest rank\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def readFile(_filePath):\r\n",
    "    \"\"\"[summary]\r\n",
    "\r\n",
    "    Args:\r\n",
    "        _filePath ([type]): [description]\r\n",
    "    \"\"\"\r\n",
    "    import pandas as pd\r\n",
    "    readFile = pd.read_csv(_filePath,index_col=0)\r\n",
    "    return(readFile)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def queryVector(query,corpus):\r\n",
    "    \"\"\"[summary]\r\n",
    "    vectorize query based on corpus\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        query ([list]): [list containing query terms]\r\n",
    "    \"\"\"\r\n",
    "    corpusList = list(corpus.index)\r\n",
    "    ## vector to track the corpusList\r\n",
    "    vector = [0]*len(corpusList)\r\n",
    "    ## format query\\r\\n\",\r\n",
    "    ## import scripts to process queries\\r\\n\"\r\n",
    "    import utils.query_processing\r\n",
    "    ## convert to string if not string\\r\\n\"\r\n",
    "    if type(query) != str:\r\n",
    "        query = ' '.join(query)\r\n",
    "    ## clean the query\r\n",
    "    query = utils.query_processing.process_query(query)\r\n",
    "\r\n",
    "    \"still lacking the query expansion\"\r\n",
    "    \"Need  glove_kv and topn to be saved in the repo\"\r\n",
    "    # query = utils.query_processing.expand_query(query)    \r\n",
    "    \r\n",
    "    ## iterate over query terms\r\n",
    "    for wordOfQuery in query:\r\n",
    "    ## variable to tract the corpus index\r\n",
    "        vectorIndex = 0\r\n",
    "    ## iterate over the all corupus\r\n",
    "        for wordOfCorpus in corpusList:\r\n",
    "            if wordOfQuery ==  wordOfCorpus:\r\n",
    "                vector[vectorIndex] += 1 \r\n",
    "    ## update courpus index\r\n",
    "            vectorIndex += 1               \r\n",
    "    return(vector)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def cosineSimilarities(queryVector,docVector):\r\n",
    "    \"    \\\"\\\"\\\"[summary]\\r\\n\"\r\n",
    "    \"    To compute the cosine similarity of the query with a single column/module in corpus\\r\\n\"\r\n",
    "    \"    Args:\\r\\n\"\r\n",
    "    \"        queryVector ([list]): [query]\\r\\n\"\r\n",
    "    \"        docVector ([list]): [description]\\r\\n\"\r\n",
    "    from scipy import spatial\r\n",
    "    distance = 1 - spatial.distance.cosine(queryVector, docVector)\r\n",
    "    return(round(distance,5))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def topModulesForEachQuery(_df):\r\n",
    "    \"[summary]\\r\\n\",\r\n",
    "    \"    To obtain the top modules for each of the query\\r\\n\"\r\n",
    "    \"    Args:\\r\\n\"\r\n",
    "    \"        _df ([dataframe]): [description] data with rows of words and columns contain the modules, the cell of the dataframe is the similarity\\r\\n\"\r\n",
    "    overallTopModules = {}\r\n",
    "    for query in _df.columns:\r\n",
    "        singleModule = {}\r\n",
    "        df.sort_values(by = query,ascending = False, inplace = True)\r\n",
    "        ## obtain top 10 modules\r\n",
    "        topModules = df[query][:10]\r\n",
    "        singleModule['topModules'] = list(topModules.index)\r\n",
    "        singleModule['topModulesScore'] = list(topModules)\r\n",
    "        overallTopModules[str(query)] = (singleModule)\r\n",
    "        \r\n",
    "    import pandas as pd\r\n",
    "    overallTopModulesDf = pd.DataFrame(overallTopModules)\r\n",
    "    return(overallTopModulesDf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    import pandas as pd\r\n",
    "    corpus = readFile('../data/course_info_scores/course_info_tf.csv') ## <-- assign the merge corupus here\r\n",
    "    # corpus = readFile('../data/course_info_with_survey_scores/course_info_with_survey_tf.csv') ## <-- assign the merge corupus here\r\n",
    "    \r\n",
    "    ## vaildation set\r\n",
    "    \"\"\"[summary]\r\n",
    "    U can contorl which vaildation set to choose to test the cosine similarity model\r\n",
    "    True : would be for the testingQuery that is self create which ensure a value when computing cosineSimilarities\r\n",
    "    False : obtain the query based on 50% of vaildation dataset which might have all cosine similarities of zero\r\n",
    "    \"\"\"\r\n",
    "    if False:\r\n",
    "        testingQuery1 = ['ability','able','abstract']\r\n",
    "        testingQuery2 = ['abstraction','accommodate','accompanies']\r\n",
    "        testingQuery3 = ['account','accounting','achieve']\r\n",
    "        testingQueryList = [[testingQuery1],[testingQuery2],[testingQuery3]]\r\n",
    "        testingQueryDf = pd.DataFrame.from_records(testingQueryList,columns = ['querySample'])\r\n",
    "        queries = testingQueryDf\r\n",
    "        \r\n",
    "    else:\r\n",
    "        vaildationQueries = readFile('../data/survey/vaildation_sample_query.csv')\r\n",
    "        queries = vaildationQueries\r\n",
    "    \r\n",
    "    ## iterate over the vaildationQueries\r\n",
    "    queriesScore = {}\r\n",
    "    for row,query in queries.T.iteritems():\r\n",
    "        print('\\nCurrent computing Query: {}'.format(query['querySample']))\r\n",
    "        singleQueryVector = queryVector(query['querySample'],corpus)\r\n",
    "        print(\"Number of terms in corpus: {}\".format(sum(singleQueryVector)))\r\n",
    "        \r\n",
    "        CosineSimilaritiesScore = []\r\n",
    "        for modules in list(corpus):\r\n",
    "            SimilaritiesScore = cosineSimilarities(singleQueryVector,corpus[modules])\r\n",
    "            CosineSimilaritiesScore.append(SimilaritiesScore)\r\n",
    "            # print(\"Score for Query on {} : {}\".format(modules,SimilaritiesScore))\r\n",
    "        queriesScore[str(query['querySample'])] = CosineSimilaritiesScore\r\n",
    "        \r\n",
    "    ## Convert to dict to df\r\n",
    "    modules = list(corpus)\r\n",
    "    df  = pd.DataFrame.from_dict(queriesScore,orient='index',columns=modules)\r\n",
    "    df = df.T\r\n",
    "    \r\n",
    "    ##obtaining top modules for each query\r\n",
    "    rankedModule = topModulesForEachQuery(df)\r\n",
    "    rankedModule\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Current computing Query: network, term, model, technology, probability\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: term, different, skill, mongodb, long\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: logistics, analysis, operation, basic, r\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: esd, network, evaluate, program, r\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: operation, basic, evaluation, price, evaluate\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: infrastructure, metric, pytorch, model, client\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: approach, logistics, shag, infrastructure, equity\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: data, sql, different, analytics, model\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: computational, best, server, certain, ec\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: sklearn, metric, demand, schedule, fundamental\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: digitalisation, skill, long, technology, aviation\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: r, hidden, artificial, schedule, simulate\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: optimisation, decision, risk, aws, jupyter\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: decentralizedapp, equity, math, ethereum, technology\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: financial, value, metric, optimize, analysis\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: risk, certain, computational, approach, c\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: markov, supply, hidden, computational, payoff\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: finance, value, long, average, business\n",
      "Number of terms in corpus: 4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\spatial\\distance.py:728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Current computing Query: financial, spark, science, focus, search\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: supply, notebook, fundamental, know, basic\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: r, linear, ethereum, c, machine\n",
      "Number of terms in corpus: 3\n",
      "\n",
      "Current computing Query: science, future, problem, demand, pytorch\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: r, ec, kera, opponent, model\n",
      "Number of terms in corpus: 2\n",
      "\n",
      "Current computing Query: markov, descent, algebra, math, research\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: clojurescript, ai, analysis, background, science\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: optimisation, opencv, risk, chain, urban\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: maing, descent, science, clojurescript, knowledge\n",
      "Number of terms in corpus: 3\n",
      "\n",
      "Current computing Query: schedule, gradient, airport, analysis, system\n",
      "Number of terms in corpus: 4\n",
      "\n",
      "Current computing Query: logistics, business, strategy, analytics, math\n",
      "Number of terms in corpus: 5\n",
      "\n",
      "Current computing Query: program, future, kera, ec, concept\n",
      "Number of terms in corpus: 4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "rankedModule"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     network, term, model, technology, probability  \\\n",
       "topModules       [50.012 Networks, 01.117 Brain-Inspired Comput...   \n",
       "topModulesScore  [0.38203, 0.32349, 0.2742, 0.2699, 0.26124, 0....   \n",
       "\n",
       "                             term, different, skill, mongodb, long  \\\n",
       "topModules       [40.240 Investment Science, 40.232 Water Resou...   \n",
       "topModulesScore  [0.13704, 0.12263, 0.09435, 0.08824, 0.08805, ...   \n",
       "\n",
       "                          logistics, analysis, operation, basic, r  \\\n",
       "topModules       [40.320 Airport Systems Planning and Design, 0...   \n",
       "topModulesScore  [0.21958, 0.13954, 0.13616, 0.11361, 0.10863, ...   \n",
       "\n",
       "                                esd, network, evaluate, program, r  \\\n",
       "topModules       [50.012 Networks, 50.035 Computer Vision, 50.0...   \n",
       "topModulesScore  [0.42712, 0.2516, 0.24957, 0.19829, 0.16388, 0...   \n",
       "\n",
       "                     operation, basic, evaluation, price, evaluate  \\\n",
       "topModules       [50.045 Information Retrieval, 40.320 Airport ...   \n",
       "topModulesScore  [0.15969, 0.15275, 0.12497, 0.12481, 0.10243, ...   \n",
       "\n",
       "                    infrastructure, metric, pytorch, model, client  \\\n",
       "topModules       [40.232 Water Resources Management, 01.117 Bra...   \n",
       "topModulesScore  [0.21936, 0.19907, 0.18685, 0.1681, 0.16663, 0...   \n",
       "\n",
       "                 approach, logistics, shag, infrastructure, equity  \\\n",
       "topModules       [40.323 Equity Valuation, 40.318 Supply Chain ...   \n",
       "topModulesScore  [0.08607, 0.0851, 0.04402, 0.03467, 0.03305, 0...   \n",
       "\n",
       "                            data, sql, different, analytics, model  \\\n",
       "topModules       [50.038 Computational Data Science, 50.043 Dat...   \n",
       "topModulesScore  [0.41958, 0.29751, 0.27372, 0.24678, 0.21776, ...   \n",
       "\n",
       "                          computational, best, server, certain, ec  \\\n",
       "topModules       [50.048 Computational Fabrication, 40.317 Fina...   \n",
       "topModulesScore  [0.23492, 0.05726, 0.04746, 0.02799, 0.01893, ...   \n",
       "\n",
       "                    sklearn, metric, demand, schedule, fundamental  ...  \\\n",
       "topModules       [40.302 Advanced Topics in Optimisation#, 40.3...  ...   \n",
       "topModulesScore  [0.14261, 0.08729, 0.08464, 0.05872, 0.04858, ...  ...   \n",
       "\n",
       "                                   r, linear, ethereum, c, machine  \\\n",
       "topModules       [50.007 Machine Learning, 40.319 Statistical a...   \n",
       "topModulesScore  [0.21668, 0.13401, 0.12897, 0.1201, 0.05243, 0...   \n",
       "\n",
       "                         science, future, problem, demand, pytorch  \\\n",
       "topModules       [50.021 Artificial Intelligence, 40.302 Advanc...   \n",
       "topModulesScore  [0.21173, 0.14261, 0.11988, 0.11349, 0.09716, ...   \n",
       "\n",
       "                                      r, ec, kera, opponent, model  \\\n",
       "topModules       [40.232 Water Resources Management, 01.117 Bra...   \n",
       "topModulesScore  [0.34684, 0.31476, 0.29544, 0.26578, 0.26347, ...   \n",
       "\n",
       "                          markov, descent, algebra, math, research  \\\n",
       "topModules       [50.048 Computational Fabrication, 40.305 Adva...   \n",
       "topModulesScore  [0.04698, 0.04508, 0.04181, 0.03753, 0.03426, ...   \n",
       "\n",
       "                  clojurescript, ai, analysis, background, science  \\\n",
       "topModules       [01.116 AI for Healthcare (Term 7), 50.038 Com...   \n",
       "topModulesScore  [0.27492, 0.13403, 0.08607, 0.05564, 0.05463, ...   \n",
       "\n",
       "                          optimisation, opencv, risk, chain, urban  \\\n",
       "topModules       [40.260 Supply Chain Management, 40.318 Supply...   \n",
       "topModulesScore  [0.2186, 0.16746, 0.11885, 0.10968, 0.08332, 0...   \n",
       "\n",
       "                 maing, descent, science, clojurescript, knowledge  \\\n",
       "topModules       [50.038 Computational Data Science, 50.021 Art...   \n",
       "topModulesScore  [0.10318, 0.0841, 0.05622, 0.04884, 0.0354, 0....   \n",
       "\n",
       "                     schedule, gradient, airport, analysis, system  \\\n",
       "topModules       [40.321 Airport Systems Modelling and Simulati...   \n",
       "topModulesScore  [0.29318, 0.21958, 0.15945, 0.08607, 0.05463, ...   \n",
       "\n",
       "                    logistics, business, strategy, analytics, math  \\\n",
       "topModules       [40.318 Supply Chain Digitalisation and Design...   \n",
       "topModulesScore  [0.22835, 0.18746, 0.08065, 0.04061, 0.03176, ...   \n",
       "\n",
       "                                program, future, kera, ec, concept  \n",
       "topModules       [40.305 Advanced Topics in Stochastic Modellin...  \n",
       "topModulesScore  [0.13525, 0.12544, 0.11785, 0.07972, 0.07538, ...  \n",
       "\n",
       "[2 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network, term, model, technology, probability</th>\n",
       "      <th>term, different, skill, mongodb, long</th>\n",
       "      <th>logistics, analysis, operation, basic, r</th>\n",
       "      <th>esd, network, evaluate, program, r</th>\n",
       "      <th>operation, basic, evaluation, price, evaluate</th>\n",
       "      <th>infrastructure, metric, pytorch, model, client</th>\n",
       "      <th>approach, logistics, shag, infrastructure, equity</th>\n",
       "      <th>data, sql, different, analytics, model</th>\n",
       "      <th>computational, best, server, certain, ec</th>\n",
       "      <th>sklearn, metric, demand, schedule, fundamental</th>\n",
       "      <th>...</th>\n",
       "      <th>r, linear, ethereum, c, machine</th>\n",
       "      <th>science, future, problem, demand, pytorch</th>\n",
       "      <th>r, ec, kera, opponent, model</th>\n",
       "      <th>markov, descent, algebra, math, research</th>\n",
       "      <th>clojurescript, ai, analysis, background, science</th>\n",
       "      <th>optimisation, opencv, risk, chain, urban</th>\n",
       "      <th>maing, descent, science, clojurescript, knowledge</th>\n",
       "      <th>schedule, gradient, airport, analysis, system</th>\n",
       "      <th>logistics, business, strategy, analytics, math</th>\n",
       "      <th>program, future, kera, ec, concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topModules</th>\n",
       "      <td>[50.012 Networks, 01.117 Brain-Inspired Comput...</td>\n",
       "      <td>[40.240 Investment Science, 40.232 Water Resou...</td>\n",
       "      <td>[40.320 Airport Systems Planning and Design, 0...</td>\n",
       "      <td>[50.012 Networks, 50.035 Computer Vision, 50.0...</td>\n",
       "      <td>[50.045 Information Retrieval, 40.320 Airport ...</td>\n",
       "      <td>[40.232 Water Resources Management, 01.117 Bra...</td>\n",
       "      <td>[40.323 Equity Valuation, 40.318 Supply Chain ...</td>\n",
       "      <td>[50.038 Computational Data Science, 50.043 Dat...</td>\n",
       "      <td>[50.048 Computational Fabrication, 40.317 Fina...</td>\n",
       "      <td>[40.302 Advanced Topics in Optimisation#, 40.3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[50.007 Machine Learning, 40.319 Statistical a...</td>\n",
       "      <td>[50.021 Artificial Intelligence, 40.302 Advanc...</td>\n",
       "      <td>[40.232 Water Resources Management, 01.117 Bra...</td>\n",
       "      <td>[50.048 Computational Fabrication, 40.305 Adva...</td>\n",
       "      <td>[01.116 AI for Healthcare (Term 7), 50.038 Com...</td>\n",
       "      <td>[40.260 Supply Chain Management, 40.318 Supply...</td>\n",
       "      <td>[50.038 Computational Data Science, 50.021 Art...</td>\n",
       "      <td>[40.321 Airport Systems Modelling and Simulati...</td>\n",
       "      <td>[40.318 Supply Chain Digitalisation and Design...</td>\n",
       "      <td>[40.305 Advanced Topics in Stochastic Modellin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topModulesScore</th>\n",
       "      <td>[0.38203, 0.32349, 0.2742, 0.2699, 0.26124, 0....</td>\n",
       "      <td>[0.13704, 0.12263, 0.09435, 0.08824, 0.08805, ...</td>\n",
       "      <td>[0.21958, 0.13954, 0.13616, 0.11361, 0.10863, ...</td>\n",
       "      <td>[0.42712, 0.2516, 0.24957, 0.19829, 0.16388, 0...</td>\n",
       "      <td>[0.15969, 0.15275, 0.12497, 0.12481, 0.10243, ...</td>\n",
       "      <td>[0.21936, 0.19907, 0.18685, 0.1681, 0.16663, 0...</td>\n",
       "      <td>[0.08607, 0.0851, 0.04402, 0.03467, 0.03305, 0...</td>\n",
       "      <td>[0.41958, 0.29751, 0.27372, 0.24678, 0.21776, ...</td>\n",
       "      <td>[0.23492, 0.05726, 0.04746, 0.02799, 0.01893, ...</td>\n",
       "      <td>[0.14261, 0.08729, 0.08464, 0.05872, 0.04858, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.21668, 0.13401, 0.12897, 0.1201, 0.05243, 0...</td>\n",
       "      <td>[0.21173, 0.14261, 0.11988, 0.11349, 0.09716, ...</td>\n",
       "      <td>[0.34684, 0.31476, 0.29544, 0.26578, 0.26347, ...</td>\n",
       "      <td>[0.04698, 0.04508, 0.04181, 0.03753, 0.03426, ...</td>\n",
       "      <td>[0.27492, 0.13403, 0.08607, 0.05564, 0.05463, ...</td>\n",
       "      <td>[0.2186, 0.16746, 0.11885, 0.10968, 0.08332, 0...</td>\n",
       "      <td>[0.10318, 0.0841, 0.05622, 0.04884, 0.0354, 0....</td>\n",
       "      <td>[0.29318, 0.21958, 0.15945, 0.08607, 0.05463, ...</td>\n",
       "      <td>[0.22835, 0.18746, 0.08065, 0.04061, 0.03176, ...</td>\n",
       "      <td>[0.13525, 0.12544, 0.11785, 0.07972, 0.07538, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}